# arXiv Search Results

**Search Query:** `("foundation model" OR "agentic" OR "multi-agent" OR "autonomous system" OR "RAG" OR "retrieval" OR "pharmacovigilance" OR "medical AI") AND (cat:cs.AI OR cat:cs.LG OR cat:cs.CL OR cat:cs.CV OR cat:cs.HC OR cat:cs.IR OR cat:cs.DC OR cat:stat.ML)`

**Date Range:** Papers published after 2025-07-10

**Generated:** 2025-10-08 02:34:13

**Total Papers Found:** 101

---

## 1. EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark

**Authors:** Deheng Zhang, Yuqian Fu, Runyi Yang, Yang Miao, Tianwen Qian, Xu Zheng, Guolei Sun, Ajad Chhatkuli, Xuanjing Huang, Yu-Gang Jiang, Luc Van Gool, Danda Pani Paudel

**Published:** 2025-10-07

**Categories:** cs.CV, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06218v1](http://arxiv.org/pdf/2510.06218v1)

**Abstract:**

Most existing benchmarks for egocentric vision understanding focus primarily
on daytime scenarios, overlooking the low-light conditions that are inevitable
in real-world applications. To investigate this gap, we present EgoNight, the
first comprehensive benchmark for nighttime egocentric vision, with visual
question answering (VQA) as the core task. A key feature of EgoNight is the
introduction of day-night aligned videos, which enhance night annotation
quality using the daytime data and reveal clear performance gaps between
lighting conditions. To achieve this, we collect both synthetic videos rendered
by Blender and real-world recordings, ensuring that scenes and actions are
visually and temporally aligned. Leveraging these paired videos, we construct
EgoNight-VQA, supported by a novel day-augmented night auto-labeling engine and
refinement through extensive human verification. Each QA pair is double-checked
by annotators for reliability. In total, EgoNight-VQA contains 3658 QA pairs
across 90 videos, spanning 12 diverse QA types, with more than 300 hours of
human work. Evaluations of state-of-the-art multimodal large language models
(MLLMs) reveal substantial performance drops when transferring from day to
night, underscoring the challenges of reasoning under low-light conditions.
Beyond VQA, EgoNight also introduces two auxiliary tasks, day-night
correspondence retrieval and egocentric depth estimation at night, that further
explore the boundaries of existing models. We believe EgoNight-VQA provides a
strong foundation for advancing application-driven egocentric vision research
and for developing models that generalize across illumination domains. All the
data and code will be made available upon acceptance.

---

## 2. TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning

**Authors:** Jiaru Zou, Soumya Roy, Vinay Kumar Verma, Ziyi Wang, David Wipf, Pan Lu, Sumit Negi, James Zou, Jingrui He

**Published:** 2025-10-07

**Categories:** cs.AI, cs.CL, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.06217v1](http://arxiv.org/pdf/2510.06217v1)

**Abstract:**

Process Reward Models (PRMs) have recently emerged as a powerful framework
for enhancing the reasoning capabilities of large reasoning models (LRMs),
particularly in the context of test-time scaling (TTS). However, their
potential for supervising LRMs on tabular reasoning domains remains
underexplored. Through detailed empirical analyses, we identify that existing
PRMs, though widely adopted for supervising text-only reasoning steps, struggle
with table-specific operations such as sub-table retrieval and schema
interaction, leading to critical performance bottlenecks. To address this
limitation, we propose TaTToo, a novel table-grounded PRM framework that (i)
reasons explicitly over tabular reasoning steps and (ii) integrates tool-based
verification to provide precise reward supervision. Concretely, we first design
a scalable data curation pipeline that constructs over 60k high-quality
step-level annotations by integrating table verification rationales with
tool-based executions. Building on the collected data, we train TaTToo with a
dual-stage paradigm: cold-start supervised fine-tuning to capture tool-use
reasoning patterns, followed by reinforcement learning with tool-grounded
reward shaping to align our model with table-based verification. We provide a
comprehensive evaluation of the policy improvement induced by our newly
designed PRM. Across 5 challenging tabular reasoning benchmarks covering
numerical reasoning, fact-checking, and data analysis, TaTToo improves
downstream policy LRMs by 30.9% at inference, surpasses strong PRM baselines
such as Qwen-2.5-Math-PRM-72B with only 8B parameters, and demonstrates strong
generalizability across diverse TTS strategies.

---

## 3. Stratified GRPO: Handling Structural Heterogeneity in Reinforcement Learning of LLM Search Agents

**Authors:** Mingkang Zhu, Xi Chen, Bei Yu, Hengshuang Zhao, Jiaya Jia

**Published:** 2025-10-07

**Categories:** cs.LG, cs.AI, cs.CL

**PDF:** [http://arxiv.org/pdf/2510.06214v1](http://arxiv.org/pdf/2510.06214v1)

**Abstract:**

Large language model (LLM) agents increasingly rely on external tools such as
search engines to solve complex, multi-step problems, and reinforcement
learning (RL) has become a key paradigm for training them. However, the
trajectories of search agents are structurally heterogeneous, where variations
in the number, placement, and outcomes of search calls lead to fundamentally
different answer directions and reward distributions. Standard policy gradient
methods, which use a single global baseline, suffer from what we identify and
formalize as cross-stratum bias-an "apples-to-oranges" comparison of
heterogeneous trajectories. This cross-stratum bias distorts credit assignment
and hinders exploration of complex, multi-step search strategies. To address
this, we propose Stratified GRPO, whose central component, Stratified Advantage
Normalization (SAN), partitions trajectories into homogeneous strata based on
their structural properties and computes advantages locally within each
stratum. This ensures that trajectories are evaluated only against their true
peers. Our analysis proves that SAN eliminates cross-stratum bias, yields
conditionally unbiased unit-variance estimates inside each stratum, and retains
the global unbiasedness and unit-variance properties enjoyed by standard
normalization, resulting in a more pure and scale-stable learning signal. To
improve practical stability under finite-sample regimes, we further linearly
blend SAN with the global estimator. Extensive experiments on diverse
single-hop and multi-hop question-answering benchmarks demonstrate that
Stratified GRPO consistently and substantially outperforms GRPO by up to 11.3
points, achieving higher training rewards, greater training stability, and more
effective search policies. These results establish stratification as a
principled remedy for structural heterogeneity in RL for LLM search agents.

---

## 4. Reference Grounded Skill Discovery

**Authors:** Seungeun Rho, Aaron Trinh, Danfei Xu, Sehoon Ha

**Published:** 2025-10-07

**Categories:** cs.LG, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06203v1](http://arxiv.org/pdf/2510.06203v1)

**Abstract:**

Scaling unsupervised skill discovery algorithms to high-DoF agents remains
challenging. As dimensionality increases, the exploration space grows
exponentially, while the manifold of meaningful skills remains limited.
Therefore, semantic meaningfulness becomes essential to effectively guide
exploration in high-dimensional spaces. In this work, we present
Reference-Grounded Skill Discovery (RGSD), a novel algorithm that grounds skill
discovery in a semantically meaningful latent space using reference data. RGSD
first performs contrastive pretraining to embed motions on a unit hypersphere,
clustering each reference trajectory into a distinct direction. This grounding
enables skill discovery to simultaneously involve both imitation of reference
behaviors and the discovery of semantically related diverse behaviors. On a
simulated SMPL humanoid with 359-D observations and 69-D actions, RGSD learns
structured skills including walking, running, punching, and side stepping, and
also discovers related novel behaviors. In downstream control tasks, RGSD
outperforms imitation-based skill acquisition baselines. Our results suggest
that lightweight reference-guided grounding offers a practical path to
discovering semantically rich and structured skills in high-DoF systems.

---

## 5. StarEmbed: Benchmarking Time Series Foundation Models on Astronomical Observations of Variable Stars

**Authors:** Weijian Li, Hong-Yu Chen, Qinjie Lin, Nabeel Rehemtulla, Ved G. Shah, Dennis Wu, Adam A. Miller, Han Liu

**Published:** 2025-10-07

**Categories:** astro-ph.SR, astro-ph.IM, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06200v1](http://arxiv.org/pdf/2510.06200v1)

**Abstract:**

Time series foundation models (TSFMs) are increasingly being adopted as
highly-capable general-purpose time series representation learners. Although
their training corpora are vast, they exclude astronomical time series data.
Observations of stars produce peta-scale time series with unique challenges
including irregular sampling and heteroskedasticity. We introduce StarEmbed,
the first public benchmark for rigorous and standardized evaluation of
state-of-the-art TSFMs on stellar time series observations (``light curves'').
We benchmark on three scientifically-motivated downstream tasks: unsupervised
clustering, supervised classification, and out-of-distribution source
detection. StarEmbed integrates a catalog of expert-vetted labels with
multi-variate light curves from the Zwicky Transient Facility, yielding ~40k
hand-labeled light curves spread across seven astrophysical classes. We
evaluate the zero-shot representation capabilities of three TSFMs (MOIRAI,
Chronos, Chronos-Bolt) and a domain-specific transformer (Astromer) against
handcrafted feature extraction, the long-standing baseline in the astrophysics
literature. Our results demonstrate that these TSFMs, especially the Chronos
models, which are trained on data completely unlike the astronomical
observations, can outperform established astrophysics-specific baselines in
some tasks and effectively generalize to entirely new data. In particular,
TSFMs deliver state-of-the-art performance on our out-of-distribution source
detection benchmark. With the first benchmark of TSFMs on astronomical time
series data, we test the limits of their generalization and motivate a paradigm
shift in time-domain astronomy from using task-specific, fully supervised
pipelines toward adopting generic foundation model representations for the
analysis of peta-scale datasets from forthcoming observatories.

---

## 6. Peeking inside the Black-Box: Reinforcement Learning for Explainable and Accurate Relation Extraction

**Authors:** Xinyu Guo, Zhengliang Shi, Minglai Yang, Mahdi Rahimi, Mihai Surdeanu

**Published:** 2025-10-07

**Categories:** cs.CL, cs.IR

**PDF:** [http://arxiv.org/pdf/2510.06198v1](http://arxiv.org/pdf/2510.06198v1)

**Abstract:**

This paper introduces a framework for relation extraction (RE) that enhances
both accuracy and explainability. The framework has two key components: (i) a
reasoning mechanism that formulates relation extraction as a series of
text-processing steps inspired by cognitive science, and (ii) an optimization
process driven by reinforcement learning (RL) with a novel reward function
designed to improve both task accuracy and explanation quality. We call our
approach CogRE. Our framework addresses the lack of supervision for
language-based explanations in traditional RE by promoting outputs that include
important relation keywords. These keywords are drawn from a high-quality
dictionary that is automatically constructed using an LLM. We evaluate our
approach for the task of one-shot RE using two LLMs and two RE datasets. Our
experiments show that CogRE improves explanation quality by addressing two
common failure patterns in one-shot RE: poor attention focus and limited
one-shot learning capability. For example, our cognitive-structured reasoning
with Qwen2.5-15B-Instruct on One-shot NYT29 achieves 24.65% F1, surpassing
prior reasoning-based designs. Optimizing this approach with RL using our
reward further improves performance by +23.46% (absolute). Finally, human
evaluation shows that our best model generates relational keywords closely
aligned with gold labels, increasing human explanation quality ratings by 54%
(relative).

---

## 7. Automated Program Repair of Uncompilable Student Code

**Authors:** Griffin Pitts, Aum Pandya, Darsh Rank, Tirth Bhatt, Muntasir Hoq, Bita Akram

**Published:** 2025-10-07

**Categories:** cs.SE, cs.AI, cs.CY

**PDF:** [http://arxiv.org/pdf/2510.06187v1](http://arxiv.org/pdf/2510.06187v1)

**Abstract:**

A significant portion of student programming submissions in CS1 learning
environments are uncompilable, limiting their use in student modeling and
downstream knowledge tracing. Traditional modeling pipelines often exclude
these cases, discarding observations of student learning. This study
investigates automated program repair as a strategy to recover uncompilable
code while preserving students' structural intent for use in student modeling.
Within this framework, we assess large language models (LLMs) as repair agents,
including GPT-5 (OpenAI), Claude 3.5 Haiku (Anthropic), and Gemini 2.5 Flash
(Google), under high- and low-context prompting conditions. Repairs were
evaluated for compilability, edit distance, and preservation of students'
original structure and logic. We find that while all three LLMs are capable of
producing compilable repairs, their behavior diverges in how well they preserve
students' control flow and code structure, which affects their pedagogical
utility. By recovering uncompilable submissions, this work enables richer and
more comprehensive analyses of learners' coding processes and development over
time.

---

## 8. RECODE-H: A Benchmark for Research Code Development with Interactive Human Feedback

**Authors:** Chunyu Miao, Henry Peng Zou, Yangning Li, Yankai Chen, Yibo Wang, Fangxin Wang, Yifan Li, Wooseong Yang, Bowei He, Xinni Zhang, Dianzhi Yu, Hanchen Yang, Hoang H Nguyen, Yue Zhou, Jie Yang, Jizhou Guo, Wenzhe Fan, Chin-Yuan Yeh, Panpan Meng, Liancheng Fang, Jinhu Qi, Wei-Chieh Huang, Zhengyao Gu, Yuwei Han, Langzhou He, Yuyao Yang, Xue Liu, Irwin King, Philip S. Yu

**Published:** 2025-10-07

**Categories:** cs.CL, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06186v1](http://arxiv.org/pdf/2510.06186v1)

**Abstract:**

Large language models (LLMs) show the promise in supporting scientific
research implementation, yet their ability to generate correct and executable
code remains limited. Existing works largely adopt one-shot settings, ignoring
the iterative and feedback-driven nature of realistic workflows of scientific
research development. To address this gap, we present RECODE-H, a benchmark of
102 tasks from research papers and repositories that evaluates LLM agents
through multi-turn interactions with LLM-simulated human feedback. It includes
structured instructions,unit tests, and a five-level feedback hierarchy to
reflect realistic researcher-agent collaboration. We further present
ReCodeAgent, a framework that integrates feedback into iterative code
generation. Experiments with leading LLMs, including GPT-5, Claude-Sonnet-4,
DeepSeek-V3.1, and Gemini 2.5, show substantial performance gains with richer
feedback, while also highlighting ongoing challenges in the generation of
complex research code. RECODE-H establishes a foundation for developing
adaptive, feedback-driven LLM agents in scientific research implementation

---

## 9. Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context

**Authors:** Yoav Gur-Arieh, Mor Geva, Atticus Geiger

**Published:** 2025-10-07

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.06182v1](http://arxiv.org/pdf/2510.06182v1)

**Abstract:**

A key component of in-context reasoning is the ability of language models
(LMs) to bind entities for later retrieval. For example, an LM might represent
"Ann loves pie" by binding "Ann" to "pie", allowing it to later retrieve "Ann"
when asked "Who loves pie?" Prior research on short lists of bound entities
found strong evidence that LMs implement such retrieval via a positional
mechanism, where "Ann" is retrieved based on its position in context. In this
work, we find that this mechanism generalizes poorly to more complex settings;
as the number of bound entities in context increases, the positional mechanism
becomes noisy and unreliable in middle positions. To compensate for this, we
find that LMs supplement the positional mechanism with a lexical mechanism
(retrieving "Ann" using its bound counterpart "pie") and a reflexive mechanism
(retrieving "Ann" through a direct pointer). Through extensive experiments on
nine models and ten binding tasks, we uncover a consistent pattern in how LMs
mix these mechanisms to drive model behavior. We leverage these insights to
develop a causal model combining all three mechanisms that estimates next token
distributions with 95% agreement. Finally, we show that our model generalizes
to substantially longer inputs of open-ended text interleaved with entity
groups, further demonstrating the robustness of our findings in more natural
settings. Overall, our study establishes a more complete picture of how LMs
bind and retrieve entities in-context.

---

## 10. TabPFN-Wide: Continued Pre-Training for Extreme Feature Counts

**Authors:** Christopher Kolberg, Katharina Eggensperger, Nico Pfeifer

**Published:** 2025-10-07

**Categories:** cs.LG

**PDF:** [http://arxiv.org/pdf/2510.06162v1](http://arxiv.org/pdf/2510.06162v1)

**Abstract:**

Revealing novel insights from the relationship between molecular measurements
and pathology remains a very impactful application of machine learning in
biomedicine. Data in this domain typically contain only a few observations but
thousands of potentially noisy features, posing challenges for conventional
machine learning approaches. While prior-data fitted networks emerge as
foundation models for tabular data, they are currently not suited to handle
large feature counts (>500). Although feature reduction enables their
application, it hinders feature importance analysis. We propose a strategy that
extends existing models through continued pre-training on synthetic data
sampled from a customized prior. The resulting model, TabPFN-Wide, matches or
exceeds its base model's performance while exhibiting improved robustness to
noise. It seamlessly scales beyond 50,000 features, regardless of noise levels,
while maintaining inherent interpretability, which is critical for biomedical
applications. Our results show that prior-informed adaptation is suitable to
enhance the capability of foundation models for high-dimensional data. On
real-world biomedical datasets many of the most relevant features identified by
the model overlap with previous biological findings, while others propose
potential starting points for future studies.

---

## 11. LLMs as Policy-Agnostic Teammates: A Case Study in Human Proxy Design for Heterogeneous Agent Teams

**Authors:** Aju Ani Justus, Chris Baber

**Published:** 2025-10-07

**Categories:** cs.LG, cs.AI, cs.HC

**PDF:** [http://arxiv.org/pdf/2510.06151v1](http://arxiv.org/pdf/2510.06151v1)

**Abstract:**

A critical challenge in modelling Heterogeneous-Agent Teams is training
agents to collaborate with teammates whose policies are inaccessible or
non-stationary, such as humans. Traditional approaches rely on expensive
human-in-the-loop data, which limits scalability. We propose using Large
Language Models (LLMs) as policy-agnostic human proxies to generate synthetic
data that mimics human decision-making. To evaluate this, we conduct three
experiments in a grid-world capture game inspired by Stag Hunt, a game theory
paradigm that balances risk and reward. In Experiment 1, we compare decisions
from 30 human participants and 2 expert judges with outputs from LLaMA 3.1 and
Mixtral 8x22B models. LLMs, prompted with game-state observations and reward
structures, align more closely with experts than participants, demonstrating
consistency in applying underlying decision criteria. Experiment 2 modifies
prompts to induce risk-sensitive strategies (e.g. "be risk averse"). LLM
outputs mirror human participants' variability, shifting between risk-averse
and risk-seeking behaviours. Finally, Experiment 3 tests LLMs in a dynamic
grid-world where the LLM agents generate movement actions. LLMs produce
trajectories resembling human participants' paths. While LLMs cannot yet fully
replicate human adaptability, their prompt-guided diversity offers a scalable
foundation for simulating policy-agnostic teammates.

---

## 12. Pushing Test-Time Scaling Limits of Deep Search with Asymmetric Verification

**Authors:** Weihao Zeng, Keqing He, Chuqiao Kuang, Xiaoguang Li, Junxian He

**Published:** 2025-10-07

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06135v1](http://arxiv.org/pdf/2510.06135v1)

**Abstract:**

Test-time compute can be scaled both sequentially and in parallel. Sequential
scaling involves lengthening the generation process, while parallel scaling
involves verifying and selecting among multiple candidate outputs. Combining
these two strategies has led to the most powerful AI systems, such as Grok 4
Heavy and GPT-5 Pro. In certain contexts (e.g., solving Sudoku puzzles),
verifying responses can be substantially easier than generating them. This
property, referred to as \emph{asymmetric verification}, highlights the strong
potential of test-time scaling (TTS). In this work, we study both sequential
and parallel TTS of deep search agents, motivated by the intuition that
verification in this setting is often much easier than generation. In
experiments, we first show that sequential scaling methods, such as budget
forcing, can be effective initially but soon degrade performance. Leveraging
asymmetric verification, however, we are able to achieve substantial
improvements by allocating only a modest amount of compute to the verifier. We
conduct experiments with flagship open-source models and extend them to their
``Heavy'' variants through TTS. These deep research agents achieve gains of up
to 27 absolute points on benchmarks such as BrowseComp. Remarkably, as an
open-source alternative, GLM-4.5 Heavy reaches accuracy of {\bf 54.0\%} on
BrowseComp and {\bf 66.0\%} on GAIA, placing it comparable to the best
proprietary choices such as OpenAI Deep Research. Tongyi-DeepResearch Heavy
further achieves {\bf 69.0\%} accuracy on BrowseComp, greatly surpassing the
best proprietary results.

---

## 13. Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation

**Authors:** Jiawei Mao, Yuhan Wang, Lifeng Chen, Can Zhao, Yucheng Tang, Dong Yang, Liangqiong Qu, Daguang Xu, Yuyin Zhou

**Published:** 2025-10-07

**Categories:** cs.CV, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06131v1](http://arxiv.org/pdf/2510.06131v1)

**Abstract:**

Recent advances in generative medical models are constrained by
modality-specific scenarios that hinder the integration of complementary
evidence from imaging, pathology, and clinical notes. This fragmentation limits
their evolution into foundation models that can learn and reason across the
full spectrum of biomedical data. We propose MeDiM, the first medical discrete
diffusion model that learns shared distributions across modalities without
modality-specific components. MeDiM unifies multiple generative tasks:
translating between images and text, and jointly producing image-report pairs
across domains in response to prompts. Built on a discrete diffusion framework,
MeDiM bridges vision and language representations through a shared
probabilistic space. To enable unified and flexible medical generation, we
employ a multimodal large language model (MLLM) as the diffusion backbone,
leveraging its prior knowledge and cross-modal reasoning. Two key designs are
introduced: (1) removing the causal attention mask for bidirectional context,
and (2) injecting continuous timestep embeddings for diffusion awareness.
Experiments demonstrate high-fidelity medical generation (FID 16.60 on
MIMIC-CXR and FID 24.19 on PathGen) and accurate report generation (METEOR
0.2650 and 0.2580). Jointly generated image-report pairs further enhance
downstream performance (plus6.43 percent BLEU-1, plus18.57 percent BLEU-2,
plus31.58 percent BLEU-3, plus4.80 percent METEOR), showing that MeDiM supports
coherent and clinically grounded multimodal outputs.

---

## 14. Constraint-Aware Route Recommendation from Natural Language via Hierarchical LLM Agents

**Authors:** Tao Zhe, Rui Liu, Fateme Memar, Xiao Luo, Wei Fan, Xinyue Ye, Zhongren Peng, Dongjie Wang

**Published:** 2025-10-07

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06078v1](http://arxiv.org/pdf/2510.06078v1)

**Abstract:**

Route recommendation aims to provide users with optimal travel plans that
satisfy diverse and complex requirements. Classical routing algorithms (e.g.,
shortest-path and constraint-aware search) are efficient but assume structured
inputs and fixed objectives, limiting adaptability to natural-language queries.
Recent LLM-based approaches enhance flexibility but struggle with spatial
reasoning and the joint modeling of route-level and POI-level preferences. To
address these limitations, we propose RouteLLM, a hierarchical multi-agent
framework that grounds natural-language intents into constraint-aware routes.
It first parses user queries into structured intents including POIs, paths, and
constraints. A manager agent then coordinates specialized sub-agents: a
constraint agent that resolves and formally check constraints, a POI agent that
retrieves and ranks candidate POIs, and a path refinement agent that refines
routes via a routing engine with preference-conditioned costs. A final verifier
agent ensures constraint satisfaction and produces the final route with an
interpretable rationale. This design bridges linguistic flexibility and spatial
structure, enabling reasoning over route feasibility and user preferences.
Experiments show that our method reliably grounds textual preferences into
constraint-aware routes, improving route quality and preference satisfaction
over classical methods.

---

## 15. Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI Models for Scatterplot-Related Tasks

**Authors:** João Palmeiro, Diogo Duarte, Rita Costa, Pedro Bizarro

**Published:** 2025-10-07

**Categories:** cs.LG, cs.AI, cs.HC

**PDF:** [http://arxiv.org/pdf/2510.06071v1](http://arxiv.org/pdf/2510.06071v1)

**Abstract:**

AI models are increasingly used for data analysis and visualization, yet
benchmarks rarely address scatterplot-specific tasks, limiting insight into
performance. To address this gap for one of the most common chart types, we
introduce a synthetic, annotated dataset of over 18,000 scatterplots from six
data generators and 17 chart designs, and a benchmark based on it. We evaluate
proprietary models from OpenAI and Google using N-shot prompting on five
distinct tasks derived from annotations of cluster bounding boxes, their center
coordinates, and outlier coordinates. OpenAI models and Gemini 2.5 Flash,
especially when prompted with examples, are viable options for counting
clusters and, in Flash's case, outliers (90%+ Accuracy). However, the results
for localization-related tasks are unsatisfactory: Precision and Recall are
near or below 50%, except for Flash in outlier identification (65.01%).
Furthermore, the impact of chart design on performance appears to be a
secondary factor, but it is advisable to avoid scatterplots with wide aspect
ratios (16:9 and 21:9) or those colored randomly. Supplementary materials are
available at https://github.com/feedzai/biy-paper.

---

## 16. Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA

**Authors:** Python Song, Luke Tenyi Chang, Yun-Yun Tsai, Penghui Li, Junfeng Yang

**Published:** 2025-10-07

**Categories:** cs.CV, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06067v1](http://arxiv.org/pdf/2510.06067v1)

**Abstract:**

CAPTCHA, originally designed to distinguish humans from robots, has evolved
into a real-world benchmark for assessing the spatial reasoning capabilities of
vision-language models. In this work, we first show that step-by-step reasoning
is crucial for vision-language models (VLMs) to solve CAPTCHAs, which represent
high-difficulty spatial reasoning tasks, and that current commercial
vision-language models still struggle with such reasoning. In particular, we
observe that most commercial VLMs (e.g., Gemini, Claude, GPT, etc.) fail to
effectively solve CAPTCHAs and thus achieve low accuracy (around 21.9 percent).
However, our findings indicate that requiring the model to perform step-by-step
reasoning before generating the final coordinates can significantly enhance its
solving accuracy, underscoring the severity of the gap. To systematically study
this issue, we introduce CAPTCHA-X, the first real-world CAPTCHA benchmark with
reasoning, covering seven categories of CAPTCHAs (such as Gobang, hCaptcha,
etc.) with step-by-step action solutions and grounding annotations. We further
define five reasoning-oriented metrics that enable a comprehensive evaluation
of models reasoning capabilities. To validate the effectiveness of reasoning,
we also propose a general agentic VLM-based framework that incorporates the
models inherent reasoning abilities. Our method achieves state-of-the-art
performance across five high-difficulty CAPTCHA types, with an average solving
accuracy of 83.9 percent, substantially surpassing existing baselines. These
results reveal the limitations of current models and highlight the importance
of reasoning in advancing visual-spatial challenges in the future.

---

## 17. Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep Research

**Authors:** Gang Liu, Yihan Zhu, Jie Chen, Meng Jiang

**Published:** 2025-10-07

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06056v1](http://arxiv.org/pdf/2510.06056v1)

**Abstract:**

Large language models hold promise as scientific assistants, yet existing
agents either rely solely on algorithm evolution or on deep research in
isolation, both of which face critical limitations. Pure algorithm evolution,
as in AlphaEvolve, depends only on the internal knowledge of LLMs and quickly
plateaus in complex domains, while pure deep research proposes ideas without
validation, resulting in unrealistic or unimplementable solutions. We present
DeepEvolve, an agent that integrates deep research with algorithm evolution,
uniting external knowledge retrieval, cross-file code editing, and systematic
debugging under a feedback-driven iterative loop. Each iteration not only
proposes new hypotheses but also refines, implements, and tests them, avoiding
both shallow improvements and unproductive over-refinements. Across nine
benchmarks in chemistry, mathematics, biology, materials, and patents,
DeepEvolve consistently improves the initial algorithm, producing executable
new algorithms with sustained gains. By bridging the gap between unguided
evolution and research without grounding, DeepEvolve provides a reliable
framework for advancing scientific algorithm discovery. Our code is available
at https://github.com/liugangcode/deepevolve.

---

## 18. Emergent AI Surveillance: Overlearned Person Re-Identification and Its Mitigation in Law Enforcement Context

**Authors:** An Thi Nguyen, Radina Stoykova, Eric Arazo

**Published:** 2025-10-07

**Categories:** cs.CV, cs.AI, cs.CY, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.06026v1](http://arxiv.org/pdf/2510.06026v1)

**Abstract:**

Generic instance search models can dramatically reduce the manual effort
required to analyze vast surveillance footage during criminal investigations by
retrieving specific objects of interest to law enforcement. However, our
research reveals an unintended emergent capability: through overlearning, these
models can single out specific individuals even when trained on datasets
without human subjects. This capability raises concerns regarding
identification and profiling of individuals based on their personal data, while
there is currently no clear standard on how de-identification can be achieved.
We evaluate two technical safeguards to curtail a model's person
re-identification capacity: index exclusion and confusion loss. Our experiments
demonstrate that combining these approaches can reduce person re-identification
accuracy to below 2% while maintaining 82% of retrieval performance for
non-person objects. However, we identify critical vulnerabilities in these
mitigations, including potential circumvention using partial person images.
These findings highlight urgent regulatory questions at the intersection of AI
governance and data protection: How should we classify and regulate systems
with emergent identification capabilities? And what technical standards should
be required to prevent identification capabilities from developing in seemingly
benign applications?

---

## 19. ARISE: An Adaptive Resolution-Aware Metric for Test-Time Scaling Evaluation in Large Reasoning Models

**Authors:** Zhangyue Yin, Qiushi Sun, Zhiyuan Zeng, Zhiyuan Yu, Qipeng Guo, Xuanjing Huang, Xipeng Qiu

**Published:** 2025-10-07

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.06014v1](http://arxiv.org/pdf/2510.06014v1)

**Abstract:**

Test-time scaling has emerged as a transformative paradigm for enhancing the
performance of large reasoning models, enabling dynamic allocation of
computational resources during inference. However, as the landscape of
reasoning models rapidly expands, a critical question remains: how can we
systematically compare and evaluate the test-time scaling capabilities across
different models? In this paper, we introduce ARISE (Adaptive Resolution-aware
Scaling Evaluation), a novel metric specifically designed to assess the
test-time scaling effectiveness of large reasoning models. Unlike existing
evaluation approaches, ARISE incorporates two key innovations: (1) sample-level
awareness that effectively penalizes negative scaling behaviors where increased
computation leads to performance degradation, and (2) a dynamic sampling
mechanism that mitigates the impact of accuracy fluctuations and token count
instability on the final assessment. We conduct comprehensive experiments
evaluating state-of-the-art reasoning models across diverse domains including
mathematical reasoning, code generation, and agentic tasks. Our results
demonstrate that ARISE provides a reliable and fine-grained measurement of
test-time scaling capabilities, revealing significant variations in scaling
efficiency across models. Notably, our evaluation identifies Claude Opus as
exhibiting superior scaling characteristics compared to other contemporary
reasoning models.

---

## 20. Hybrid Quantum-Classical Policy Gradient for Adaptive Control of Cyber-Physical Systems: A Comparative Study of VQC vs. MLP

**Authors:** Aueaphum Aueawatthanaphisut, Nyi Wunna Tun

**Published:** 2025-10-07

**Categories:** quant-ph, cs.AI, cs.LG, cs.RO, cs.SY, eess.SY

**PDF:** [http://arxiv.org/pdf/2510.06010v1](http://arxiv.org/pdf/2510.06010v1)

**Abstract:**

The comparative evaluation between classical and quantum reinforcement
learning (QRL) paradigms was conducted to investigate their convergence
behavior, robustness under observational noise, and computational efficiency in
a benchmark control environment. The study employed a multilayer perceptron
(MLP) agent as a classical baseline and a parameterized variational quantum
circuit (VQC) as a quantum counterpart, both trained on the CartPole-v1
environment over 500 episodes. Empirical results demonstrated that the
classical MLP achieved near-optimal policy convergence with a mean return of
498.7 +/- 3.2, maintaining stable equilibrium throughout training. In contrast,
the VQC exhibited limited learning capability, with an average return of 14.6
+/- 4.8, primarily constrained by circuit depth and qubit connectivity. Noise
robustness analysis further revealed that the MLP policy deteriorated
gracefully under Gaussian perturbations, while the VQC displayed higher
sensitivity at equivalent noise levels. Despite the lower asymptotic
performance, the VQC exhibited significantly lower parameter count and
marginally increased training time, highlighting its potential scalability for
low-resource quantum processors. The results suggest that while classical
neural policies remain dominant in current control benchmarks, quantum-enhanced
architectures could offer promising efficiency advantages once hardware noise
and expressivity limitations are mitigated.

---

## 21. Deterministic Legal Retrieval: An Action API for Querying the SAT-Graph RAG

**Authors:** Hudson de Martim

**Published:** 2025-10-07

**Categories:** cs.AI, cs.CL, cs.IR

**PDF:** [http://arxiv.org/pdf/2510.06002v1](http://arxiv.org/pdf/2510.06002v1)

**Abstract:**

The Structure-Aware Temporal Graph RAG (SAT-Graph RAG) addresses core
limitations of standard Retrieval-Augmented Generation in the legal domain by
providing a verifiable knowledge graph that models hierarchical structure,
temporal evolution, and causal events of legal norms. However, a critical gap
remains: how to reliably query this structured knowledge without sacrificing
its deterministic properties. This paper introduces the SAT-Graph API, a formal
query execution layer centered on canonical actions-atomic, composable, and
auditable primitives that isolate probabilistic discovery from deterministic
retrieval. These actions enable: (i) high-precision hybrid search; (ii) robust
reference resolution; (iii) point-in-time version retrieval; and (iv) auditable
causal tracing. We demonstrate how planner-guided agents can decompose complex
queries into Directed Acyclic Graphs (DAGs) of these actions. This two-layer
architecture transforms retrieval from an opaque black box to a transparent,
auditable process, directly addressing Explainable AI (XAI) requirements for
high-stakes domains.

---

## 22. Information-Theoretic Policy Pre-Training with Empowerment

**Authors:** Moritz Schneider, Robert Krug, Narunas Vaskevicius, Luigi Palmieri, Michael Volpp, Joschka Boedecker

**Published:** 2025-10-07

**Categories:** cs.AI, cs.IT, cs.LG, cs.RO, math.IT

**PDF:** [http://arxiv.org/pdf/2510.05996v1](http://arxiv.org/pdf/2510.05996v1)

**Abstract:**

Empowerment, an information-theoretic measure of an agent's potential
influence on its environment, has emerged as a powerful intrinsic motivation
and exploration framework for reinforcement learning (RL). Besides for
unsupervised RL and skill learning algorithms, the specific use of empowerment
as a pre-training signal has received limited attention in the literature. We
show that empowerment can be used as a pre-training signal for data-efficient
downstream task adaptation. For this we extend the traditional notion of
empowerment by introducing discounted empowerment, which balances the agent's
control over the environment across short- and long-term horizons. Leveraging
this formulation, we propose a novel pre-training paradigm that initializes
policies to maximize discounted empowerment, enabling agents to acquire a
robust understanding of environmental dynamics. We analyze empowerment-based
pre-training for various existing RL algorithms and empirically demonstrate its
potential as a general-purpose initialization strategy: empowerment-maximizing
policies with long horizons are data-efficient and effective, leading to
improved adaptability in downstream tasks. Our findings pave the way for future
research to scale this framework to high-dimensional and complex tasks, further
advancing the field of RL.

---

## 23. Diffusion Models for Low-Light Image Enhancement: A Multi-Perspective Taxonomy and Performance Analysis

**Authors:** Eashan Adhikarla, Yixin Liu, Brian D. Davison

**Published:** 2025-10-07

**Categories:** cs.CV, cs.AI, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05976v1](http://arxiv.org/pdf/2510.05976v1)

**Abstract:**

Low-light image enhancement (LLIE) is vital for safety-critical applications
such as surveillance, autonomous navigation, and medical imaging, where
visibility degradation can impair downstream task performance. Recently,
diffusion models have emerged as a promising generative paradigm for LLIE due
to their capacity to model complex image distributions via iterative denoising.
This survey provides an up-to-date critical analysis of diffusion models for
LLIE, distinctively featuring an in-depth comparative performance evaluation
against Generative Adversarial Network and Transformer-based state-of-the-art
methods, a thorough examination of practical deployment challenges, and a
forward-looking perspective on the role of emerging paradigms like foundation
models. We propose a multi-perspective taxonomy encompassing six categories:
Intrinsic Decomposition, Spectral & Latent, Accelerated, Guided, Multimodal,
and Autonomous; that map enhancement methods across physical priors,
conditioning schemes, and computational efficiency. Our taxonomy is grounded in
a hybrid view of both the model mechanism and the conditioning signals. We
evaluate qualitative failure modes, benchmark inconsistencies, and trade-offs
between interpretability, generalization, and inference efficiency. We also
discuss real-world deployment constraints (e.g., memory, energy use) and
ethical considerations. This survey aims to guide the next generation of
diffusion-based LLIE research by highlighting trends and surfacing open
research questions, including novel conditioning, real-time adaptation, and the
potential of foundation models.

---

## 24. How public datasets constrain the development of diversity-aware news recommender systems, and what law could do about it

**Authors:** Max van Drunen, Sanne Vrijenhoek

**Published:** 2025-10-07

**Categories:** cs.IR

**PDF:** [http://arxiv.org/pdf/2510.05952v1](http://arxiv.org/pdf/2510.05952v1)

**Abstract:**

News recommender systems increasingly determine what news individuals see
online. Over the past decade, researchers have extensively critiqued
recommender systems that prioritise news based on user engagement. To offer an
alternative, researchers have analysed how recommender systems could support
the media's ability to fulfil its role in democratic society by recommending
news based on editorial values, particularly diversity. However, there
continues to be a large gap between normative theory on how news recommender
systems should incorporate diversity, and technical literature that designs
such systems. We argue that to realise diversity-aware recommender systems in
practice, it is crucial to pay attention to the datasets that are needed to
train modern news recommenders. We aim to make two main contributions. First,
we identify the information a dataset must include to enable the development of
the diversity-aware news recommender systems proposed in normative literature.
Based on this analysis, we assess the limitations of currently available public
datasets, and show what potential they do have to expand research into
diversity-aware recommender systems. Second, we analyse why and how European
law and policy can be used to provide researchers with structural access to the
data they need to develop diversity-aware news recommender systems.

---

## 25. Training-Free Time Series Classification via In-Context Reasoning with LLM Agents

**Authors:** Songyuan Sui, Zihang Xu, Yu-Neng Chuang, Kwei-Herng Lai, Xia Hu

**Published:** 2025-10-07

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05950v1](http://arxiv.org/pdf/2510.05950v1)

**Abstract:**

Time series classification (TSC) spans diverse application scenarios, yet
labeled data are often scarce, making task-specific training costly and
inflexible. Recent reasoning-oriented large language models (LLMs) show promise
in understanding temporal patterns, but purely zero-shot usage remains
suboptimal. We propose FETA, a multi-agent framework for training-free TSC via
exemplar-based in-context reasoning. FETA decomposes a multivariate series into
channel-wise subproblems, retrieves a few structurally similar labeled examples
for each channel, and leverages a reasoning LLM to compare the query against
these exemplars, producing channel-level labels with self-assessed confidences;
a confidence-weighted aggregator then fuses all channel decisions. This design
eliminates the need for pretraining or fine-tuning, improves efficiency by
pruning irrelevant channels and controlling input length, and enhances
interpretability through exemplar grounding and confidence estimation. On nine
challenging UEA datasets, FETA achieves strong accuracy under a fully
training-free setting, surpassing multiple trained baselines. These results
demonstrate that a multi-agent in-context reasoning framework can transform
LLMs into competitive, plug-and-play TSC solvers without any parameter
training. The code is available at https://github.com/SongyuanSui/FETATSC.

---

## 26. EARL: Efficient Agentic Reinforcement Learning Systems for Large Language Models

**Authors:** Zheyue Tan, Mustapha Abdullahi, Tuo Shi, Huining Yuan, Zelai Xu, Chao Yu, Boxun Li, Bo Zhao

**Published:** 2025-10-07

**Categories:** cs.DC, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05943v1](http://arxiv.org/pdf/2510.05943v1)

**Abstract:**

Reinforcement learning (RL) has become a pivotal component of large language
model (LLM) post-training, and agentic RL extends this paradigm to operate as
agents through multi-turn interaction and tool use. Scaling such systems
exposes two practical bottlenecks: (1) context length grows rapidly during
training, inflating memory usage and latency, and triggering out-of-memory
(OOM) failures; and (2) intermediate tensors accumulate with context length,
making cross-device data movement a major system bottleneck.
  We present EARL, a scalable system for efficient agentic RL. EARL designs a
parallelism selector that dynamically adapts model and training parallelism
across RL stages based on sequence length and system load, and a data
dispatcher that performs layout-aware, decentralized exchange of intermediate
data batches. Together, these components increase throughput, reduce
long-context failures, and enable stable large-scale training of agentic LLMs
without relying on hard limits or penalties of context length.

---

## 27. LLM-FS-Agent: A Deliberative Role-based Large Language Model Architecture for Transparent Feature Selection

**Authors:** Mohamed Bal-Ghaoui, Fayssal Sabri

**Published:** 2025-10-07

**Categories:** cs.LG, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05935v1](http://arxiv.org/pdf/2510.05935v1)

**Abstract:**

High-dimensional data remains a pervasive challenge in machine learning,
often undermining model interpretability and computational efficiency. While
Large Language Models (LLMs) have shown promise for dimensionality reduction
through feature selection, existing LLM-based approaches frequently lack
structured reasoning and transparent justification for their decisions. This
paper introduces LLM-FS-Agent, a novel multi-agent architecture designed for
interpretable and robust feature selection. The system orchestrates a
deliberative "debate" among multiple LLM agents, each assigned a specific role,
enabling collective evaluation of feature relevance and generation of detailed
justifications. We evaluate LLM-FS-Agent in the cybersecurity domain using the
CIC-DIAD 2024 IoT intrusion detection dataset and compare its performance
against strong baselines, including LLM-Select and traditional methods such as
PCA. Experimental results demonstrate that LLM-FS-Agent consistently achieves
superior or comparable classification performance while reducing downstream
training time by an average of 46% (statistically significant improvement, p =
0.028 for XGBoost). These findings highlight that the proposed deliberative
architecture enhances both decision transparency and computational efficiency,
establishing LLM-FS-Agent as a practical and reliable solution for real-world
applications.

---

## 28. Prompt reinforcing for long-term planning of large language models

**Authors:** Hsien-Chin Lin, Benjamin Matthias Ruppik, Carel van Niekerk, Chia-Hao Shen, Michael Heck, Nurul Lubis, Renato Vukovic, Shutong Feng, Milica Gašić

**Published:** 2025-10-07

**Categories:** cs.CL, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05921v1](http://arxiv.org/pdf/2510.05921v1)

**Abstract:**

Large language models (LLMs) have achieved remarkable success in a wide range
of natural language processing tasks and can be adapted through prompting.
However, they remain suboptimal in multi-turn interactions, often relying on
incorrect early assumptions and failing to track user goals over time, which
makes such tasks particularly challenging. Prior works in dialogue systems have
shown that long-term planning is essential for handling interactive tasks. In
this work, we propose a prompt optimisation framework inspired by reinforcement
learning, which enables such planning to take place by only modifying the task
instruction prompt of the LLM-based agent. By generating turn-by-turn feedback
and leveraging experience replay for prompt rewriting, our proposed method
shows significant improvement in multi-turn tasks such as text-to-SQL and
task-oriented dialogue. Moreover, it generalises across different LLM-based
agents and can leverage diverse LLMs as meta-prompting agents. This warrants
future research in reinforcement learning-inspired parameter-free optimisation
methods.

---

## 29. The Safety Challenge of World Models for Embodied AI Agents: A Review

**Authors:** Lorenzo Baraldi, Zifan Zeng, Chongzhe Zhang, Aradhana Nayak, Hongbo Zhu, Feng Liu, Qunli Zhang, Peng Wang, Shiming Liu, Zheng Hu, Angelo Cangelosi, Lorenzo Baraldi

**Published:** 2025-10-07

**Categories:** cs.AI, cs.CV, cs.RO

**PDF:** [http://arxiv.org/pdf/2510.05865v1](http://arxiv.org/pdf/2510.05865v1)

**Abstract:**

The rapid progress in embodied artificial intelligence has highlighted the
necessity for more advanced and integrated models that can perceive, interpret,
and predict environmental dynamics. In this context, World Models (WMs) have
been introduced to provide embodied agents with the abilities to anticipate
future environmental states and fill in knowledge gaps, thereby enhancing
agents' ability to plan and execute actions. However, when dealing with
embodied agents it is fundamental to ensure that predictions are safe for both
the agent and the environment. In this article, we conduct a comprehensive
literature review of World Models in the domains of autonomous driving and
robotics, with a specific focus on the safety implications of scene and control
generation tasks. Our review is complemented by an empirical analysis, wherein
we collect and examine predictions from state-of-the-art models, identify and
categorize common faults (herein referred to as pathologies), and provide a
quantitative evaluation of the results.

---

## 30. Evaluating the Sensitivity of LLMs to Harmful Contents in Long Input

**Authors:** Faeze Ghorbanpour, Alexander Fraser

**Published:** 2025-10-07

**Categories:** cs.CL, cs.CY

**PDF:** [http://arxiv.org/pdf/2510.05864v1](http://arxiv.org/pdf/2510.05864v1)

**Abstract:**

Large language models (LLMs) increasingly support applications that rely on
extended context, from document processing to retrieval-augmented generation.
While their long-context capabilities are well studied for reasoning and
retrieval, little is known about their behavior in safety-critical scenarios.
We evaluate LLMs' sensitivity to harmful content under extended context,
varying type (explicit vs. implicit), position (beginning, middle, end),
prevalence (0.01-0.50 of the prompt), and context length (600-6000 tokens).
Across harmful content categories such as toxic, offensive, and hate speech,
with LLaMA-3, Qwen-2.5, and Mistral, we observe similar patterns: performance
peaks at moderate harmful prevalence (0.25) but declines when content is very
sparse or dominant; recall decreases with increasing context length; harmful
sentences at the beginning are generally detected more reliably; and explicit
content is more consistently recognized than implicit. These findings provide
the first systematic view of how LLMs prioritize and calibrate harmful content
in long contexts, highlighting both their emerging strengths and the challenges
that remain for safety-critical use.

---

## 31. StereoSync: Spatially-Aware Stereo Audio Generation from Video

**Authors:** Christian Marinoni, Riccardo Fosco Gramaccioni, Kazuki Shimada, Takashi Shibuya, Yuki Mitsufuji, Danilo Comminiello

**Published:** 2025-10-07

**Categories:** cs.SD, cs.CV, cs.LG, cs.MM, eess.AS

**PDF:** [http://arxiv.org/pdf/2510.05828v1](http://arxiv.org/pdf/2510.05828v1)

**Abstract:**

Although audio generation has been widely studied over recent years,
video-aligned audio generation still remains a relatively unexplored frontier.
To address this gap, we introduce StereoSync, a novel and efficient model
designed to generate audio that is both temporally synchronized with a
reference video and spatially aligned with its visual context. Moreover,
StereoSync also achieves efficiency by leveraging pretrained foundation models,
reducing the need for extensive training while maintaining high-quality
synthesis. Unlike existing methods that primarily focus on temporal
synchronization, StereoSync introduces a significant advancement by
incorporating spatial awareness into video-aligned audio generation. Indeed,
given an input video, our approach extracts spatial cues from depth maps and
bounding boxes, using them as cross-attention conditioning in a diffusion-based
audio generation model. Such an approach allows StereoSync to go beyond simple
synchronization, producing stereo audio that dynamically adapts to the spatial
structure and movement of a video scene. We evaluate StereoSync on Walking The
Maps, a curated dataset comprising videos from video games that feature
animated characters walking through diverse environments. Experimental results
demonstrate the ability of StereoSync to achieve both temporal and spatial
alignment, advancing the state of the art in video-to-audio generation and
resulting in a significantly more immersive and realistic audio experience.

---

## 32. VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation

**Authors:** Haoran Zhang, Shuanghao Bai, Wanqi Zhou, Yuedi Zhang, Qi Zhang, Pengxiang Ding, Cheng Chi, Donglin Wang, Badong Chen

**Published:** 2025-10-07

**Categories:** cs.RO, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05827v1](http://arxiv.org/pdf/2510.05827v1)

**Abstract:**

Robotic grasping is one of the most fundamental tasks in robotic
manipulation, and grasp detection/generation has long been the subject of
extensive research. Recently, language-driven grasp generation has emerged as a
promising direction due to its practical interaction capabilities. However,
most existing approaches either lack sufficient reasoning and generalization
capabilities or depend on complex modular pipelines. Moreover, current grasp
foundation models tend to overemphasize dialog and object semantics, resulting
in inferior performance and restriction to single-object grasping. To maintain
strong reasoning ability and generalization in cluttered environments, we
propose VCoT-Grasp, an end-to-end grasp foundation model that incorporates
visual chain-of-thought reasoning to enhance visual understanding for grasp
generation. VCoT-Grasp adopts a multi-turn processing paradigm that dynamically
focuses on visual inputs while providing interpretable reasoning traces. For
training, we refine and introduce a large-scale dataset, VCoT-GraspSet,
comprising 167K synthetic images with over 1.36M grasps, as well as 400+
real-world images with more than 1.2K grasps, annotated with intermediate
bounding boxes. Extensive experiments on both VCoT-GraspSet and real robot
demonstrate that our method significantly improves grasp success rates and
generalizes effectively to unseen objects, backgrounds, and distractors. More
details can be found at https://zhanghr2001.github.io/VCoT-Grasp.github.io.

---

## 33. ConstraintLLM: A Neuro-Symbolic Framework for Industrial-Level Constraint Programming

**Authors:** Weichun Shi, Minghao Liu, Wanting Zhang, Langchen Shi, Fuqi Jia, Feifei Ma, Jian Zhang

**Published:** 2025-10-07

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05774v1](http://arxiv.org/pdf/2510.05774v1)

**Abstract:**

Constraint programming (CP) is a crucial technology for solving real-world
constraint optimization problems (COPs), with the advantages of rich modeling
semantics and high solving efficiency. Using large language models (LLMs) to
generate formal modeling automatically for COPs is becoming a promising
approach, which aims to build trustworthy neuro-symbolic AI with the help of
symbolic solvers. However, CP has received less attention compared to works
based on operations research (OR) models. We introduce ConstraintLLM, the first
LLM specifically designed for CP modeling, which is trained on an open-source
LLM with multi-instruction supervised fine-tuning. We propose the
Constraint-Aware Retrieval Module (CARM) to increase the in-context learning
capabilities, which is integrated in a Tree-of-Thoughts (ToT) framework with
guided self-correction mechanism. Moreover, we construct and release IndusCP,
the first industrial-level benchmark for CP modeling, which contains 140
challenging tasks from various domains. Our experiments demonstrate that
ConstraintLLM achieves state-of-the-art solving accuracy across multiple
benchmarks and outperforms the baselines by 2x on the new IndusCP benchmark.
Code and data are available at: https://github.com/william4s/ConstraintLLM.

---

## 34. RareAgent: Self-Evolving Reasoning for Drug Repurposing in Rare Diseases

**Authors:** Lang Qin, Zijian Gan, Xu Cao, Pengcheng Jiang, Yankai Jiang, Jiawei Han, Kaishun Wu, Jintai Chen

**Published:** 2025-10-07

**Categories:** cs.AI, cs.MA

**PDF:** [http://arxiv.org/pdf/2510.05764v1](http://arxiv.org/pdf/2510.05764v1)

**Abstract:**

Computational drug repurposing for rare diseases is especially challenging
when no prior associations exist between drugs and target diseases. Therefore,
knowledge graph completion and message-passing GNNs have little reliable signal
to learn and propagate, resulting in poor performance. We present RareAgent, a
self-evolving multi-agent system that reframes this task from passive pattern
recognition to active evidence-seeking reasoning. RareAgent organizes
task-specific adversarial debates in which agents dynamically construct
evidence graphs from diverse perspectives to support, refute, or entail
hypotheses. The reasoning strategies are analyzed post hoc in a
self-evolutionary loop, producing textual feedback that refines agent policies,
while successful reasoning paths are distilled into transferable heuristics to
accelerate future investigations. Comprehensive evaluations reveal that
RareAgent improves the indication AUPRC by 18.1% over reasoning baselines and
provides a transparent reasoning chain consistent with clinical evidence.

---

## 35. OneVision: An End-to-End Generative Framework for Multi-view E-commerce Vision Search

**Authors:** Zexin Zheng, Huangyu Dai, Lingtao Mao, Xinyu Sun, Zihan Liang, Ben Chen, Yuqing Ding, Chenyi Lei, Wenwu Ou, Han Li, Kun Gai

**Published:** 2025-10-07

**Categories:** cs.CV

**PDF:** [http://arxiv.org/pdf/2510.05759v1](http://arxiv.org/pdf/2510.05759v1)

**Abstract:**

Traditional vision search, similar to search and recommendation systems,
follows the multi-stage cascading architecture (MCA) paradigm to balance
efficiency and conversion. Specifically, the query image undergoes feature
extraction, recall, pre-ranking, and ranking stages, ultimately presenting the
user with semantically similar products that meet their preferences. This
multi-view representation discrepancy of the same object in the query and the
optimization objective collide across these stages, making it difficult to
achieve Pareto optimality in both user experience and conversion. In this
paper, an end-to-end generative framework, OneVision, is proposed to address
these problems. OneVision builds on VRQ, a vision-aligned residual quantization
encoding, which can align the vastly different representations of an object
across multiple viewpoints while preserving the distinctive features of each
product as much as possible. Then a multi-stage semantic alignment scheme is
adopted to maintain strong visual similarity priors while effectively
incorporating user-specific information for personalized preference generation.
In offline evaluations, OneVision performs on par with online MCA, while
improving inference efficiency by 21% through dynamic pruning. In A/B tests, it
achieves significant online improvements: +2.15% item CTR, +2.27% CVR, and
+3.12% order volume. These results demonstrate that a semantic ID centric,
generative architecture can unify retrieval and personalization while
simplifying the serving pathway.

---

## 36. Transcribing Rhythmic Patterns of the Guitar Track in Polyphonic Music

**Authors:** Aleksandr Lukoianov, Anssi Klapuri

**Published:** 2025-10-07

**Categories:** cs.SD, cs.LG, eess.AS

**PDF:** [http://arxiv.org/pdf/2510.05756v1](http://arxiv.org/pdf/2510.05756v1)

**Abstract:**

Whereas chord transcription has received considerable attention during the
past couple of decades, far less work has been devoted to transcribing and
encoding the rhythmic patterns that occur in a song. The topic is especially
relevant for instruments such as the rhythm guitar, which is typically played
by strumming rhythmic patterns that repeat and vary over time. However, in many
cases one cannot objectively define a single "right" rhythmic pattern for a
given song section. To create a dataset with well-defined ground-truth labels,
we asked expert musicians to transcribe the rhythmic patterns in 410 popular
songs and record cover versions where the guitar tracks followed those
transcriptions. To transcribe the strums and their corresponding rhythmic
patterns, we propose a three-step framework. Firstly, we perform approximate
stem separation to extract the guitar part from the polyphonic mixture.
Secondly, we detect individual strums within the separated guitar audio, using
a pre-trained foundation model (MERT) as a backbone. Finally, we carry out a
pattern-decoding process in which the transcribed sequence of guitar strums is
represented by patterns drawn from an expert-curated vocabulary. We show that
it is possible to transcribe the rhythmic patterns of the guitar track in
polyphonic music with quite high accuracy, producing a representation that is
human-readable and includes automatically detected bar lines and time signature
markers. We perform ablation studies and error analysis and propose a set of
evaluation metrics to assess the accuracy and readability of the predicted
rhythmic pattern sequence.

---

## 37. Empirical Comparison of Membership Inference Attacks in Deep Transfer Learning

**Authors:** Yuxuan Bai, Gauri Pradhan, Marlon Tobaben, Antti Honkela

**Published:** 2025-10-07

**Categories:** cs.LG, cs.CR

**PDF:** [http://arxiv.org/pdf/2510.05753v1](http://arxiv.org/pdf/2510.05753v1)

**Abstract:**

With the emergence of powerful large-scale foundation models, the training
paradigm is increasingly shifting from from-scratch training to transfer
learning. This enables high utility training with small, domain-specific
datasets typical in sensitive applications.Membership inference attacks (MIAs)
provide an empirical estimate of the privacy leakage by machine learning
models. Yet, prior assessments of MIAs against models fine-tuned with transfer
learning rely on a small subset of possible attacks. We address this by
comparing performance of diverse MIAs in transfer learning settings to help
practitioners identify the most efficient attacks for privacy risk evaluation.
We find that attack efficacy decreases with the increase in training data for
score-based MIAs. We find that there is no one MIA which captures all privacy
risks in models trained with transfer learning. While the Likelihood Ratio
Attack (LiRA) demonstrates superior performance across most experimental
scenarios, the Inverse Hessian Attack (IHA) proves to be more effective against
models fine-tuned on PatchCamelyon dataset in high data regime.

---

## 38. ALISE: Annotation-Free LiDAR Instance Segmentation for Autonomous Driving

**Authors:** Yongxuan Lyu, Guangfeng Jiang, Hongsi Liu, Jun Liu

**Published:** 2025-10-07

**Categories:** cs.CV

**PDF:** [http://arxiv.org/pdf/2510.05752v1](http://arxiv.org/pdf/2510.05752v1)

**Abstract:**

The manual annotation of outdoor LiDAR point clouds for instance segmentation
is extremely costly and time-consuming. Current methods attempt to reduce this
burden but still rely on some form of human labeling. To completely eliminate
this dependency, we introduce ALISE, a novel framework that performs LiDAR
instance segmentation without any annotations. The central challenge is to
generate high-quality pseudo-labels in a fully unsupervised manner. Our
approach starts by employing Vision Foundation Models (VFMs), guided by text
and images, to produce initial pseudo-labels. We then refine these labels
through a dedicated spatio-temporal voting module, which combines 2D and 3D
semantics for both offline and online optimization. To achieve superior feature
learning, we further introduce two forms of semantic supervision: a set of 2D
prior-based losses that inject visual knowledge into the 3D network, and a
novel prototype-based contrastive loss that builds a discriminative feature
space by exploiting 3D semantic consistency. This comprehensive design results
in significant performance gains, establishing a new state-of-the-art for
unsupervised 3D instance segmentation. Remarkably, our approach even
outperforms MWSIS, a method that operates with supervision from ground-truth
(GT) 2D bounding boxes by a margin of 2.53% in mAP (50.95% vs. 48.42%).

---

## 39. Communication Enables Cooperation in LLM Agents: A Comparison with Curriculum-Based Approaches

**Authors:** Hachem Madmoun, Salem Lahlou

**Published:** 2025-10-07

**Categories:** cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05748v1](http://arxiv.org/pdf/2510.05748v1)

**Abstract:**

Eliciting cooperation in multi-agent LLM systems is critical for AI
alignment. We investigate two approaches: direct communication and curriculum
learning. In a 4-player Stag Hunt, a one-word "cheap talk" channel increases
cooperation from 0% to 48.3%, demonstrating communication as a robust
coordination mechanism. In contrast, we find that curriculum learning is highly
sensitive to design choices: our pedagogical curriculum through progressively
complex games reduced agent payoffs by 27.4% in an Iterated Public Goods Game
with Punishment. Qualitative analysis reveals that curricula emphasizing
defection-equilibrium games can induce "learned pessimism" in agents. These
findings suggest that for coordination problems, simple communication protocols
may be more reliable than experience-based training, and that curriculum design
for social dilemmas requires careful attention to the strategic lessons
embedded in game sequences.

---

## 40. ARM: Discovering Agentic Reasoning Modules for Generalizable Multi-Agent Systems

**Authors:** Bohan Yao, Shiva Krishna Reddy Malay, Vikas Yadav

**Published:** 2025-10-07

**Categories:** cs.AI, cs.CL, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05746v1](http://arxiv.org/pdf/2510.05746v1)

**Abstract:**

Large Language Model (LLM)-powered Multi-agent systems (MAS) have achieved
state-of-the-art results on various complex reasoning tasks. Recent works have
proposed techniques to automate the design of MASes, eliminating the need for
manual engineering. However, these techniques perform poorly, often achieving
similar or inferior performance to simple baselines. Furthermore, they require
computationally expensive re-discovery of architectures for each new task
domain and expensive data annotation on domains without existing labeled
validation sets. A critical insight is that simple Chain of Thought (CoT)
reasoning often performs competitively with these complex systems, suggesting
that the fundamental reasoning unit of MASes, CoT, warrants further
investigation. To this end, we present a new paradigm for automatic MAS design
that pivots the focus to optimizing CoT reasoning. We introduce the Agentic
Reasoning Module (ARM), an agentic generalization of CoT where each granular
reasoning step is executed by a specialized reasoning module. This module is
discovered through a tree search over the code space, starting from a simple
CoT module and evolved using mutations informed by reflection on execution
traces. The resulting ARM acts as a versatile reasoning building block which
can be utilized as a direct recursive loop or as a subroutine in a learned
meta-orchestrator. Our approach significantly outperforms both manually
designed MASes and state-of-the-art automatic MAS design methods. Crucially,
MASes built with ARM exhibit superb generalization, maintaining high
performance across different foundation models and task domains without further
optimization.

---

## 41. Artificially intelligent agents in the social and behavioral sciences: A history and outlook

**Authors:** Petter Holme, Milena Tsvetkova

**Published:** 2025-10-07

**Categories:** cs.AI, cs.CY

**PDF:** [http://arxiv.org/pdf/2510.05743v1](http://arxiv.org/pdf/2510.05743v1)

**Abstract:**

We review the historical development and current trends of artificially
intelligent agents (agentic AI) in the social and behavioral sciences: from the
first programmable computers, and social simulations soon thereafter, to
today's experiments with large language models. This overview emphasizes the
role of AI in the scientific process and the changes brought about, both
through technological advancements and the broader evolution of science from
around 1950 to the present. Some of the specific points we cover include: the
challenges of presenting the first social simulation studies to a world unaware
of computers, the rise of social systems science, intelligent game theoretic
agents, the age of big data and the epistemic upheaval in its wake, and the
current enthusiasm around applications of generative AI, and many other topics.
A pervasive theme is how deeply entwined we are with the technologies we use to
understand ourselves.

---

## 42. Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect

**Authors:** Amirtaha Amanzadi, Zahra Dehghanian, Hamid Beigy, Hamid R. Rabiee

**Published:** 2025-10-07

**Categories:** cs.CV, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05740v1](http://arxiv.org/pdf/2510.05740v1)

**Abstract:**

The rapid development of generative models has made it increasingly crucial
to develop detectors that can reliably detect synthetic images. Although most
of the work has now focused on cross-generator generalization, we argue that
this viewpoint is too limited. Detecting synthetic images involves another
equally important challenge: generalization across visual domains. To bridge
this gap,we present the OmniGen Benchmark. This comprehensive evaluation
dataset incorporates 12 state-of-the-art generators, providing a more realistic
way of evaluating detector performance under realistic conditions. In addition,
we introduce a new method, FusionDetect, aimed at addressing both vectors of
generalization. FusionDetect draws on the benefits of two frozen foundation
models: CLIP & Dinov2. By deriving features from both complementary models,we
develop a cohesive feature space that naturally adapts to changes in both
thecontent and design of the generator. Our extensive experiments demonstrate
that FusionDetect delivers not only a new state-of-the-art, which is 3.87% more
accurate than its closest competitor and 6.13% more precise on average on
established benchmarks, but also achieves a 4.48% increase in accuracy on
OmniGen,along with exceptional robustness to common image perturbations. We
introduce not only a top-performing detector, but also a new benchmark and
framework for furthering universal AI image detection. The code and dataset are
available at http://github.com/amir-aman/FusionDetect

---

## 43. FinReflectKG - EvalBench: Benchmarking Financial KG with Multi-Dimensional Evaluation

**Authors:** Fabrizio Dimino, Abhinav Arun, Bhaskarjit Sarmah, Stefano Pasquali

**Published:** 2025-10-07

**Categories:** q-fin.CP, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05710v1](http://arxiv.org/pdf/2510.05710v1)

**Abstract:**

Large language models (LLMs) are increasingly being used to extract
structured knowledge from unstructured financial text. Although prior studies
have explored various extraction methods, there is no universal benchmark or
unified evaluation framework for the construction of financial knowledge graphs
(KG). We introduce FinReflectKG - EvalBench, a benchmark and evaluation
framework for KG extraction from SEC 10-K filings. Building on the agentic and
holistic evaluation principles of FinReflectKG - a financial KG linking audited
triples to source chunks from S&P 100 filings and supporting single-pass,
multi-pass, and reflection-agent-based extraction modes - EvalBench implements
a deterministic commit-then-justify judging protocol with explicit bias
controls, mitigating position effects, leniency, verbosity and world-knowledge
reliance. Each candidate triple is evaluated with binary judgments of
faithfulness, precision, and relevance, while comprehensiveness is assessed on
a three-level ordinal scale (good, partial, bad) at the chunk level. Our
findings suggest that, when equipped with explicit bias controls, LLM-as-Judge
protocols provide a reliable and cost-efficient alternative to human
annotation, while also enabling structured error analysis. Reflection-based
extraction emerges as the superior approach, achieving best performance in
comprehensiveness, precision, and relevance, while single-pass extraction
maintains the highest faithfulness. By aggregating these complementary
dimensions, FinReflectKG - EvalBench enables fine-grained benchmarking and
bias-aware evaluation, advancing transparency and governance in financial AI
applications.

---

## 44. Oracle-Guided Masked Contrastive Reinforcement Learning for Visuomotor Policies

**Authors:** Yuhang Zhang, Jiaping Xiao, Chao Yan, Mir Feroskhan

**Published:** 2025-10-07

**Categories:** cs.RO, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05692v1](http://arxiv.org/pdf/2510.05692v1)

**Abstract:**

A prevailing approach for learning visuomotor policies is to employ
reinforcement learning to map high-dimensional visual observations directly to
action commands. However, the combination of high-dimensional visual inputs and
agile maneuver outputs leads to long-standing challenges, including low sample
efficiency and significant sim-to-real gaps. To address these issues, we
propose Oracle-Guided Masked Contrastive Reinforcement Learning (OMC-RL), a
novel framework designed to improve the sample efficiency and asymptotic
performance of visuomotor policy learning. OMC-RL explicitly decouples the
learning process into two stages: an upstream representation learning stage and
a downstream policy learning stage. In the upstream stage, a masked Transformer
module is trained with temporal modeling and contrastive learning to extract
temporally-aware and task-relevant representations from sequential visual
inputs. After training, the learned encoder is frozen and used to extract
visual representations from consecutive frames, while the Transformer module is
discarded. In the downstream stage, an oracle teacher policy with privileged
access to global state information supervises the agent during early training
to provide informative guidance and accelerate early policy learning. This
guidance is gradually reduced to allow independent exploration as training
progresses. Extensive experiments in simulated and real-world environments
demonstrate that OMC-RL achieves superior sample efficiency and asymptotic
policy performance, while also improving generalization across diverse and
perceptually complex scenarios.

---

## 45. DecEx-RAG: Boosting Agentic Retrieval-Augmented Generation with Decision and Execution Optimization via Process Supervision

**Authors:** Yongqi Leng, Yikun Lei, Xikai Liu, Meizhi Zhong, Bojian Xiong, Yurong Zhang, Yan Gao, Yi Wu, Yao Hu, Deyi Xiong

**Published:** 2025-10-07

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05691v1](http://arxiv.org/pdf/2510.05691v1)

**Abstract:**

Agentic Retrieval-Augmented Generation (Agentic RAG) enhances the processing
capability for complex tasks through dynamic retrieval and adaptive workflows.
Recent advances (e.g., Search-R1) have shown that outcome-supervised
reinforcement learning demonstrate strong performance. However, this approach
still suffers from inefficient exploration, sparse reward signals, and
ambiguous global reward feedback. To address these challenges, we propose
DecEx-RAG, which models RAG as a Markov Decision Process (MDP) incorporating
decision-making and execution, while introducing an efficient pruning strategy
to optimize data expansion. Through comprehensive process-level policy
optimization, DecEx-RAG significantly enhances the autonomous task
decomposition, dynamic retrieval, and high-quality answer generation
capabilities of large language models (LLMs). Experiments show that DecEx-RAG
achieves an average absolute performance improvement of $6.2\%$ across six
datasets, significantly outperforming existing baselines. Moreover, the pruning
strategy improves data construction efficiency by nearly $6 \times$, providing
an efficient solution for process-supervised RAG training. The code is
available at https://github.com/sdsxdxl/DecEx-RAG.

---

## 46. EduVerse: A User-Defined Multi-Agent Simulation Space for Education Scenario

**Authors:** Yiping Ma, Shiyu Hu, Buyuan Zhu, Yipei Wang, Yaxuan Kang, Shiqing Liu, Kang Hao Cheong

**Published:** 2025-10-07

**Categories:** cs.CV, cs.CY

**PDF:** [http://arxiv.org/pdf/2510.05650v1](http://arxiv.org/pdf/2510.05650v1)

**Abstract:**

Reproducing cognitive development, group interaction, and long-term evolution
in virtual classrooms remains a core challenge for educational AI, as real
classrooms integrate open-ended cognition, dynamic social interaction,
affective factors, and multi-session development rarely captured together.
Existing approaches mostly focus on short-term or single-agent settings,
limiting systematic study of classroom complexity and cross-task reuse. We
present EduVerse, the first user-defined multi-agent simulation space that
supports environment, agent, and session customization. A distinctive
human-in-the-loop interface further allows real users to join the space. Built
on a layered CIE (Cognition-Interaction-Evolution) architecture, EduVerse
ensures individual consistency, authentic interaction, and longitudinal
adaptation in cognition, emotion, and behavior-reproducing realistic classroom
dynamics with seamless human-agent integration. We validate EduVerse in
middle-school Chinese classes across three text genres, environments, and
multiple sessions. Results show: (1) Instructional alignment: simulated IRF
rates (0.28-0.64) closely match real classrooms (0.37-0.49), indicating
pedagogical realism; (2) Group interaction and role differentiation: network
density (0.27-0.40) with about one-third of peer links realized, while
human-agent tasks indicate a balance between individual variability and
instructional stability; (3) Cross-session evolution: the positive transition
rate R+ increase by 11.7% on average, capturing longitudinal shifts in
behavior, emotion, and cognition and revealing structured learning
trajectories. Overall, EduVerse balances realism, reproducibility, and
interpretability, providing a scalable platform for educational AI. The system
will be open-sourced to foster cross-disciplinary research.

---

## 47. Generative AI-Driven Hierarchical Multi-Agent Framework for Zero-Touch Optical Networks

**Authors:** Yao Zhang, Yuchen Song, Shengnan Li, Yan Shi, Shikui Shen, Xiongyan Tang, Min Zhang, Danshi Wang

**Published:** 2025-10-07

**Categories:** cs.NI, cs.AI, cs.CL, cs.MA, cs.SY, eess.SY

**PDF:** [http://arxiv.org/pdf/2510.05625v1](http://arxiv.org/pdf/2510.05625v1)

**Abstract:**

The rapid development of Generative Artificial Intelligence (GenAI) has
catalyzed a transformative technological revolution across all walks of life.
As the backbone of wideband communication, optical networks are expecting
high-level autonomous operation and zero-touch management to accommodate their
expanding network scales and escalating transmission bandwidth. The integration
of GenAI is deemed as the pivotal solution for realizing zero-touch optical
networks. However, the lifecycle management of optical networks involves a
multitude of tasks and necessitates seamless collaboration across multiple
layers, which poses significant challenges to the existing single-agent GenAI
systems. In this paper, we propose a GenAI-driven hierarchical multi-agent
framework designed to streamline multi-task autonomous execution for zero-touch
optical networks. We present the architecture, implementation, and applications
of this framework. A field-deployed mesh network is utilized to demonstrate
three typical scenarios throughout the lifecycle of optical network: quality of
transmission estimation in the planning stage, dynamic channel adding/dropping
in the operation stage, and system capacity increase in the upgrade stage. The
case studies, illustrate the capabilities of multi-agent framework in
multi-task allocation, coordination, execution, evaluation, and summarization.
This work provides a promising approach for the future development of
intelligent, efficient, and collaborative network management solutions, paving
the way for more specialized and adaptive zero-touch optical networks.

---

## 48. Limitations of Current Evaluation Practices for Conversational Recommender Systems and the Potential of User Simulation

**Authors:** Nolwenn Bernard, Krisztian Balog

**Published:** 2025-10-07

**Categories:** cs.IR

**PDF:** [http://arxiv.org/pdf/2510.05624v1](http://arxiv.org/pdf/2510.05624v1)

**Abstract:**

Research and development on conversational recommender systems (CRSs)
critically depends on sound and reliable evaluation methodologies. However, the
interactive nature of these systems poses significant challenges for automatic
evaluation. This paper critically examines current evaluation practices and
identifies two key limitations: the over-reliance on static test collections
and the inadequacy of existing evaluation metrics. To substantiate this
critique, we analyze real user interactions with nine existing CRSs and
demonstrate a striking disconnect between self-reported user satisfaction and
performance scores reported in prior literature. To address these limitations,
this work explores the potential of user simulation to generate dynamic
interaction data, offering a departure from static datasets. Furthermore, we
propose novel evaluation metrics, based on a general reward/cost framework,
designed to better align with real user satisfaction. Our analysis of different
simulation approaches provides valuable insights into their effectiveness and
reveals promising initial results, showing improved correlation with system
rankings compared to human evaluation. While these findings indicate a
significant step forward in CRS evaluation, we also identify areas for future
research and refinement in both simulation techniques and evaluation metrics.

---

## 49. Decoupling Correctness from Policy: A Deterministic Causal Structure for Multi-Agent Systems

**Authors:** Zhiyuan Ren, Tao Zhang, Wenchi Chen

**Published:** 2025-10-07

**Categories:** cs.DC, cs.MA

**PDF:** [http://arxiv.org/pdf/2510.05621v1](http://arxiv.org/pdf/2510.05621v1)

**Abstract:**

In distributed multi-agent systems, correctness is often entangled with
operational policies such as scheduling, batching, or routing, which makes
systems brittle since performance-driven policy evolution may break integrity
guarantees. This paper introduces the Deterministic Causal Structure (DCS), a
formal foundation that decouples correctness from policy. We develop a minimal
axiomatic theory and prove four results: existence and uniqueness,
policy-agnostic invariance, observational equivalence, and axiom minimality.
These results show that DCS resolves causal ambiguities that value-centric
convergence models such as CRDTs cannot address, and that removing any axiom
collapses determinism into ambiguity. DCS thus emerges as a boundary principle
of asynchronous computation, analogous to CAP and FLP: correctness is preserved
only within the expressive power of a join-semilattice. All guarantees are
established by axioms and proofs, with only minimal illustrative constructions
included to aid intuition. This work establishes correctness as a fixed,
policy-agnostic substrate, a Correctness-as-a-Chassis paradigm, on which
distributed intelligent systems can be built modularly, safely, and evolvably.

---

## 50. InstaGeo: Compute-Efficient Geospatial Machine Learning from Data to Deployment

**Authors:** Ibrahim Salihu Yusuf, Iffanice Houndayi, Rym Oualha, Mohamed Aziz Cherif, Kobby Panford-Quainoo, Arnu Pretorius

**Published:** 2025-10-07

**Categories:** cs.CV, cs.CY, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05617v1](http://arxiv.org/pdf/2510.05617v1)

**Abstract:**

Open-access multispectral imagery from missions like Landsat 8-9 and
Sentinel-2 has fueled the development of geospatial foundation models (GFMs)
for humanitarian and environmental applications. Yet, their deployment remains
limited by (i) the absence of automated geospatial data pipelines and (ii) the
large size of fine-tuned models. Existing GFMs lack workflows for processing
raw satellite imagery, and downstream adaptations often retain the full
complexity of the original encoder.
  We present InstaGeo, an open-source, end-to-end framework that addresses
these challenges by integrating: (1) automated data curation to transform raw
imagery into model-ready datasets; (2) task-specific model distillation to
derive compact, compute-efficient models; and (3) seamless deployment as
interactive web-map applications. Using InstaGeo, we reproduced datasets from
three published studies and trained models with marginal mIoU differences of
-0.73 pp for flood mapping, -0.20 pp for crop segmentation, and +1.79 pp for
desert locust prediction. The distilled models are up to 8x smaller than
standard fine-tuned counterparts, reducing FLOPs and CO2 emissions with minimal
accuracy loss.
  Leveraging InstaGeo's streamlined data pipeline, we also curated a larger
crop segmentation dataset, achieving a state-of-the-art mIoU of 60.65%, a 12 pp
improvement over prior baselines. Moreover, InstaGeo enables users to progress
from raw data to model deployment within a single working day.
  By unifying data preparation, model compression, and deployment, InstaGeo
transforms research-grade GFMs into practical, low-carbon tools for real-time,
large-scale Earth observation. This approach shifts geospatial AI toward data
quality and application-driven innovation. Source code, datasets, and model
checkpoints are available at:
https://github.com/instadeepai/InstaGeo-E2E-Geospatial-ML.git

---

## 51. MADIAVE: Multi-Agent Debate for Implicit Attribute Value Extraction

**Authors:** Wei-Chieh Huang, Cornelia Caragea

**Published:** 2025-10-07

**Categories:** cs.CL, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05611v1](http://arxiv.org/pdf/2510.05611v1)

**Abstract:**

Implicit Attribute Value Extraction (AVE) is essential for accurately
representing products in e-commerce, as it infers lantent attributes from
multimodal data. Despite advances in multimodal large language models (MLLMs),
implicit AVE remains challenging due to the complexity of multidimensional data
and gaps in vision-text understanding. In this work, we introduce
\textsc{\modelname}, a multi-agent debate framework that employs multiple MLLM
agents to iteratively refine inferences. Through a series of debate rounds,
agents verify and update each other's responses, thereby improving inference
performance and robustness. Experiments on the ImplicitAVE dataset demonstrate
that even a few rounds of debate significantly boost accuracy, especially for
attributes with initially low performance. We systematically evaluate various
debate configurations, including identical or different MLLM agents, and
analyze how debate rounds affect convergence dynamics. Our findings highlight
the potential of multi-agent debate strategies to address the limitations of
single-agent approaches and offer a scalable solution for implicit AVE in
multimodal e-commerce.

---

## 52. A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks

**Authors:** Shuzheng Si, Haozhe Zhao, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun

**Published:** 2025-10-07

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05608v1](http://arxiv.org/pdf/2510.05608v1)

**Abstract:**

Agents based on large language models (LLMs) struggle with brainless
trial-and-error and generating hallucinatory actions due to a lack of global
planning in long-horizon tasks. In this paper, we introduce a plan-and-execute
framework and propose EAGLET, an efficient and effective planner training
method to enhance the executor agent's planning abilities without human effort.
Specifically, we train a plug-and-play global planner through a two-step
process: we first synthesize high-quality plans from an advanced LLM using our
proposed homologous consensus filtering strategy, and apply fine-tuning as a
cold start. Moreover, we further improve the planner with a rule-based
reinforcement learning stage using a novel executor capability gain reward,
ensuring it can handle task instructions of varying difficulty. Experiments on
three long-horizon agent tasks show that executor agents equipped with our
planner outperform existing methods, achieving new state-of-the-art
performance. Meanwhile, EAGLET reduces training costs by 8x compared to
RL-based baselines, and it does not require manual effort or extra training
data, offering an efficient and effective solution.

---

## 53. AutoPentester: An LLM Agent-based Framework for Automated Pentesting

**Authors:** Yasod Ginige, Akila Niroshan, Sajal Jain, Suranga Seneviratne

**Published:** 2025-10-07

**Categories:** cs.CR, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05605v1](http://arxiv.org/pdf/2510.05605v1)

**Abstract:**

Penetration testing and vulnerability assessment are essential industry
practices for safeguarding computer systems. As cyber threats grow in scale and
complexity, the demand for pentesting has surged, surpassing the capacity of
human professionals to meet it effectively. With advances in AI, particularly
Large Language Models (LLMs), there have been attempts to automate the
pentesting process. However, existing tools such as PentestGPT are still
semi-manual, requiring significant professional human interaction to conduct
pentests. To this end, we propose a novel LLM agent-based framework,
AutoPentester, which automates the pentesting process. Given a target IP,
AutoPentester automatically conducts pentesting steps using common security
tools in an iterative process. It can dynamically generate attack strategies
based on the tool outputs from the previous iteration, mimicking the human
pentester approach. We evaluate AutoPentester using Hack The Box and
custom-made VMs, comparing the results with the state-of-the-art PentestGPT.
Results show that AutoPentester achieves a 27.0% better subtask completion rate
and 39.5% more vulnerability coverage with fewer steps. Most importantly, it
requires significantly fewer human interactions and interventions compared to
PentestGPT. Furthermore, we recruit a group of security industry professional
volunteers for a user survey and perform a qualitative analysis to evaluate
AutoPentester against industry practices and compare it with PentestGPT. On
average, AutoPentester received a score of 3.93 out of 5 based on user reviews,
which was 19.8% higher than PentestGPT.

---

## 54. AgentDR Dynamic Recommendation with Implicit Item-Item Relations via LLM-based Agents

**Authors:** Mingdai Yang, Nurendra Choudhary, Jiangshu Du, Edward W. Huang, Philip S. Yu, Karthik Subbian, Danai Kourta

**Published:** 2025-10-07

**Categories:** cs.IR, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05598v1](http://arxiv.org/pdf/2510.05598v1)

**Abstract:**

Recent agent-based recommendation frameworks aim to simulate user behaviors
by incorporating memory mechanisms and prompting strategies, but they struggle
with hallucinating non-existent items and full-catalog ranking. Besides, a
largely underexplored opportunity lies in leveraging LLMs'commonsense reasoning
to capture user intent through substitute and complement relationships between
items, which are usually implicit in datasets and difficult for traditional
ID-based recommenders to capture. In this work, we propose a novel LLM-agent
framework, AgenDR, which bridges LLM reasoning with scalable recommendation
tools. Our approach delegates full-ranking tasks to traditional models while
utilizing LLMs to (i) integrate multiple recommendation outputs based on
personalized tool suitability and (ii) reason over substitute and complement
relationships grounded in user history. This design mitigates hallucination,
scales to large catalogs, and enhances recommendation relevance through
relational reasoning. Through extensive experiments on three public grocery
datasets, we show that our framework achieves superior full-ranking
performance, yielding on average a twofold improvement over its underlying
tools. We also introduce a new LLM-based evaluation metric that jointly
measures semantic alignment and ranking correctness.

---

## 55. From Agentification to Self-Evolving Agentic AI for Wireless Networks: Concepts, Approaches, and Future Research Directions

**Authors:** Changyuan Zhao, Ruichen Zhang, Jiacheng Wang, Dusit Niyato, Geng Sun, Xianbin Wang, Shiwen Mao, Abbas Jamalipour

**Published:** 2025-10-07

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05596v1](http://arxiv.org/pdf/2510.05596v1)

**Abstract:**

Self-evolving agentic artificial intelligence (AI) offers a new paradigm for
future wireless systems by enabling autonomous agents to continually adapt and
improve without human intervention. Unlike static AI models, self-evolving
agents embed an autonomous evolution cycle that updates models, tools, and
workflows in response to environmental dynamics. This paper presents a
comprehensive overview of self-evolving agentic AI, highlighting its layered
architecture, life cycle, and key techniques, including tool intelligence,
workflow optimization, self-reflection, and evolutionary learning. We further
propose a multi-agent cooperative self-evolving agentic AI framework, where
multiple large language models (LLMs) are assigned role-specialized prompts
under the coordination of a supervisor agent. Through structured dialogue,
iterative feedback, and systematic validation, the system autonomously executes
the entire life cycle without human intervention. A case study on antenna
evolution in low-altitude wireless networks (LAWNs) demonstrates how the
framework autonomously upgrades fixed antenna optimization into movable antenna
optimization. Experimental results show that the proposed self-evolving agentic
AI autonomously improves beam gain and restores degraded performance by up to
52.02%, consistently surpassing the fixed baseline with little to no human
intervention and validating its adaptability and robustness for next-generation
wireless intelligence.

---

## 56. Improving Chain-of-Thought Efficiency for Autoregressive Image Generation

**Authors:** Zeqi Gu, Markos Georgopoulos, Xiaoliang Dai, Marjan Ghazvininejad, Chu Wang, Felix Juefei-Xu, Kunpeng Li, Yujun Shi, Zecheng He, Zijian He, Jiawei Zhou, Abe Davis, Jialiang Wang

**Published:** 2025-10-07

**Categories:** cs.CV, cs.AI, cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05593v1](http://arxiv.org/pdf/2510.05593v1)

**Abstract:**

Autoregressive multimodal large language models have recently gained
popularity for image generation, driven by advances in foundation models. To
enhance alignment and detail, newer approaches employ chain-of-thought (CoT)
reasoning, expanding user inputs into elaborated prompts prior to image
synthesis. However, this strategy can introduce unnecessary redundancy -- a
phenomenon we call visual overthinking -- which increases computational costs
and can introduce details that contradict the original prompt. In this work, we
explore how to generate more concise CoT sequences for more efficient image
generation. We introduce ShortCoTI, a lightweight optimization framework that
encourages more concise CoT while preserving output image quality. ShortCoTI
rewards more concise prompts with an adaptive function that scales according to
an estimated difficulty for each task. Incorporating this reward into a
reinforcement learning paradigm reduces prompt reasoning length by 54% while
maintaining or slightly improving quality metrics across multiple benchmarks
(T2I-CompBench, GenEval). Qualitative analysis shows that our method eliminates
verbose explanations and repetitive refinements, producing reasoning prompts
that are both concise and semantically rich. As a result, ShortCoTI improves
computational efficiency without compromising the fidelity or visual appeal of
generated images.

---

## 57. In-the-Flow Agentic System Optimization for Effective Planning and Tool Use

**Authors:** Zhuofeng Li, Haoxiang Zhang, Seungju Han, Sheng Liu, Jianwen Xie, Yu Zhang, Yejin Choi, James Zou, Pan Lu

**Published:** 2025-10-07

**Categories:** cs.AI, cs.CL, cs.LG, cs.MA

**PDF:** [http://arxiv.org/pdf/2510.05592v1](http://arxiv.org/pdf/2510.05592v1)

**Abstract:**

Outcome-driven reinforcement learning has advanced reasoning in large
language models (LLMs), but prevailing tool-augmented approaches train a
single, monolithic policy that interleaves thoughts and tool calls under full
context; this scales poorly with long horizons and diverse tools and
generalizes weakly to new scenarios. Agentic systems offer a promising
alternative by decomposing work across specialized modules, yet most remain
training-free or rely on offline training decoupled from the live dynamics of
multi-turn interaction. We introduce AgentFlow, a trainable, in-the-flow
agentic framework that coordinates four modules (planner, executor, verifier,
generator) through an evolving memory and directly optimizes its planner inside
the multi-turn loop. To train on-policy in live environments, we propose
Flow-based Group Refined Policy Optimization (Flow-GRPO), which tackles
long-horizon, sparse-reward credit assignment by converting multi-turn
optimization into a sequence of tractable single-turn policy updates. It
broadcasts a single, verifiable trajectory-level outcome to every turn to align
local planner decisions with global success and stabilizes learning with
group-normalized advantages. Across ten benchmarks, AgentFlow with a 7B-scale
backbone outperforms top-performing baselines with average accuracy gains of
14.9% on search, 14.0% on agentic, 14.5% on mathematical, and 4.1% on
scientific tasks, even surpassing larger proprietary models like GPT-4o.
Further analyses confirm the benefits of in-the-flow optimization, showing
improved planning, enhanced tool-calling reliability, and positive scaling with
model size and reasoning turns.

---

## 58. CalibCLIP: Contextual Calibration of Dominant Semantics for Text-Driven Image Retrieval

**Authors:** Bin Kang, Bin Chen, Junjie Wang, Yulin Li, Junzhi Zhao, Zhuotao Tian

**Published:** 2025-10-07

**Categories:** cs.CV

**PDF:** [http://arxiv.org/pdf/2510.05586v1](http://arxiv.org/pdf/2510.05586v1)

**Abstract:**

Existing Visual Language Models (VLMs) suffer structural limitations where a
few low contribution tokens may excessively capture global semantics,
dominating the information aggregation process and suppressing the
discriminative features in text-driven image retrieval tasks. To address this,
we introduce \textbf{CalibCLIP}, a training-free method designed to calibrate
the suppressive effect of dominant tokens. Specifically, in the visual space,
we propose the Contrastive Visual Enhancer (CVE), which decouples visual
features into target and low information regions. Subsequently, it identifies
dominant tokens and dynamically suppresses their representations.In the textual
space, we introduce the Discriminative Concept Calibrator (DCC), which aims to
differentiate between general and discriminative concepts within the text
query. By mitigating the challenges posed by generic concepts and improving the
representations of discriminative concepts, DCC strengthens the differentiation
among similar samples. Finally, extensive experiments demonstrate consistent
improvements across seven benchmarks spanning three image retrieval tasks,
underscoring the effectiveness of CalibCLIP. Code is available at:
https://github.com/kangbin98/CalibCLIP

---

## 59. MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption

**Authors:** Chen Li, Zhantao Yang, Han Zhang, Fangyi Chen, Chenchen Zhu, Anudeepsekhar Bolimera, Marios Savvides

**Published:** 2025-10-07

**Categories:** cs.AI, cs.RO

**PDF:** [http://arxiv.org/pdf/2510.05580v1](http://arxiv.org/pdf/2510.05580v1)

**Abstract:**

Vision-Language-Action (VLA) models show promise in embodied reasoning, yet
remain far from true generalists-they often require task-specific fine-tuning,
and generalize poorly to unseen tasks. We propose MetaVLA, a unified,
backbone-agnostic post-training framework for efficient and scalable alignment.
MetaVLA introduces Context-Aware Meta Co-Training, which consolidates diverse
target tasks into a single fine-tuning stage while leveraging structurally
diverse auxiliary tasks to improve in-domain generalization. Unlike naive
multi-task SFT, MetaVLA integrates a lightweight meta-learning
mechanism-derived from Attentive Neural Processes-to enable rapid adaptation
from diverse contexts with minimal architectural change or inference overhead.
On the LIBERO benchmark, MetaVLA with six auxiliary tasks outperforms OpenVLA
by up to 8.0% on long-horizon tasks, reduces training steps from 240K to 75K,
and cuts GPU time by ~76%. These results show that scalable, low-resource
post-training is achievable-paving the way toward general-purpose embodied
agents. Code will be available.

---

## 60. Mission Impossible: Feedback-Guided Dynamic Interactive Planning for Improving Reasoning on LLMs

**Authors:** Dong Yan, Gaochen Wu, Bowen Zhou

**Published:** 2025-10-07

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05577v1](http://arxiv.org/pdf/2510.05577v1)

**Abstract:**

Recent advancements in language agents have led to significant improvements
in multi-hop reasoning tasks. However, existing approaches often struggle with
handling open-domain problems, which require massive information retrieval due
to their reliance on a fixed sequence of actions. To address this, we propose
Feedback-Guided Dynamic Interactive Planning (FGDIP), a novel framework
tailored to enhance reasoning in LLMs by utilizing dynamic and adaptive
strategies for information exploration in open-domain multi-hop reasoning
tasks. Our approach begins by identifying key entities relevant to the problem,
which serve as the initial nodes in the reasoning process. From these initial
nodes, we then generate reasoning child nodes with the process being refined
through a combination of historical error analysis and real-time feedback,
which allows the framework to dynamically adjust and optimize its reasoning
strategies. By integrating depth-first search with an innovative node
generation technique, our framework adapts based on both prior error paths and
concurrently generated nodes at the same hierarchical level. This dynamic
strategy effectively expands the search space while ensuring the reasoning
process systematically converges toward accurate solutions. Experimental
results show that FGDIP achieved up to 54.47% F1 score on the HotpotQA dataset
and 70.05% on the StrategyQA dataset, surpassing the best baseline by 5.03% and
7.25% respectively, highlighting its versatility and potential to enhance
language agents in multi-hop reasoning tasks.

---

## 61. Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations

**Authors:** Chengzhi Liu, Yuzhe Yang, Kaiwen Zhou, Zhen Zhang, Yue Fan, Yannan Xie, Peng Qi, Xin Eric Wang

**Published:** 2025-10-07

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05571v1](http://arxiv.org/pdf/2510.05571v1)

**Abstract:**

The promotion of academic papers has become an important means of enhancing
research visibility. However, existing automated methods struggle limited
storytelling, insufficient aesthetic quality, and constrained self-adjustment,
making it difficult to achieve efficient and engaging dissemination. At the
heart of those challenges is a simple principle: \emph{there is no way to
improve it when you cannot evaluate it right}. To address this, we introduce
\textbf{EvoPresent}, a self-improvement agent framework that unifies coherent
narratives, aesthetic-aware designs, and realistic presentation delivery via
virtual characters. Central to EvoPresent is \textbf{PresAesth}, a multi-task
reinforcement learning (RL) aesthetic model that provides reliable aesthetic
scoring, defect adjustment, and comparative feedback, enabling iterative
self-improvement even under limited aesthetic training data. To systematically
evaluate the methods, we introduce \textbf{EvoPresent Benchmark}, a
comprehensive benchmark comprising: \textit{Presentation Generation Quality},
built on 650 top-tier AI conference papers with multimodal resources (slides,
videos and scripts) to assess both content and design; and \textit{Aesthetic
Awareness}, consisting of 2,000 slide pairs with varying aesthetic levels,
supporting joint training and evaluation on scoring, defect adjustment, and
comparison. Our findings highlight that (i) High-quality feedback is essential
for agent self-improvement, while initial capability alone does not guarantee
effective self-correction. (ii) Automated generation pipelines exhibit a
trade-off between visual design and content construction. (iii) Multi-task RL
training shows stronger generalization in aesthetic awareness tasks.

---

## 62. Toward Systems Foundations for Agentic Exploration

**Authors:** Jiakai Xu, Tianle Zhou, Eugene Wu, Kostis Kaffes

**Published:** 2025-10-07

**Categories:** cs.DC, cs.OS

**PDF:** [http://arxiv.org/pdf/2510.05556v1](http://arxiv.org/pdf/2510.05556v1)

**Abstract:**

Agentic exploration, letting LLM-powered agents branch, backtrack, and search
across many execution paths, demands systems support well beyond today's
pass-at-k resets. Our benchmark of six snapshot/restore mechanisms shows that
generic tools such as CRIU or container commits are not fast enough even in
isolated testbeds, and they crumble entirely in real deployments where agents
share files, sockets, and cloud APIs with other agents and human users. In this
talk, we pinpoint three open fundamental challenges: fork semantics, which
concerns how branches reveal or hide tentative updates; external side-effects,
where fork awareness must be added to services or their calls intercepted; and
native forking, which requires cloning databases and runtimes in microseconds
without bulk copying.

---

## 63. KEO: Knowledge Extraction on OMIn via Knowledge Graphs and RAG for Safety-Critical Aviation Maintenance

**Authors:** Kuangshi Ai, Jonathan A. Karr Jr, Meng Jiang, Nitesh V. Chawla, Chaoli Wang

**Published:** 2025-10-07

**Categories:** cs.CL, cs.IR

**PDF:** [http://arxiv.org/pdf/2510.05524v1](http://arxiv.org/pdf/2510.05524v1)

**Abstract:**

We present Knowledge Extraction on OMIn (KEO), a domain-specific knowledge
extraction and reasoning framework with large language models (LLMs) in
safety-critical contexts. Using the Operations and Maintenance Intelligence
(OMIn) dataset, we construct a QA benchmark spanning global sensemaking and
actionable maintenance tasks. KEO builds a structured Knowledge Graph (KG) and
integrates it into a retrieval-augmented generation (RAG) pipeline, enabling
more coherent, dataset-wide reasoning than traditional text-chunk RAG. We
evaluate locally deployable LLMs (Gemma-3, Phi-4, Mistral-Nemo) and employ
stronger models (GPT-4o, Llama-3.3) as judges. Experiments show that KEO
markedly improves global sensemaking by revealing patterns and system-level
insights, while text-chunk RAG remains effective for fine-grained procedural
tasks requiring localized retrieval. These findings underscore the promise of
KG-augmented LLMs for secure, domain-specific QA and their potential in
high-stakes reasoning.

---

## 64. CAM: A Constructivist View of Agentic Memory for LLM-Based Reading Comprehension

**Authors:** Rui Li, Zeyu Zhang, Xiaohe Bo, Zihang Tian, Xu Chen, Quanyu Dai, Zhenhua Dong, Ruiming Tang

**Published:** 2025-10-07

**Categories:** cs.CL, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05520v1](http://arxiv.org/pdf/2510.05520v1)

**Abstract:**

Current Large Language Models (LLMs) are confronted with overwhelming
information volume when comprehending long-form documents. This challenge
raises the imperative of a cohesive memory module, which can elevate vanilla
LLMs into autonomous reading agents. Despite the emergence of some heuristic
approaches, a systematic design principle remains absent. To fill this void, we
draw inspiration from Jean Piaget's Constructivist Theory, illuminating three
traits of the agentic memory -- structured schemata, flexible assimilation, and
dynamic accommodation. This blueprint forges a clear path toward a more robust
and efficient memory system for LLM-based reading comprehension. To this end,
we develop CAM, a prototype implementation of Constructivist Agentic Memory
that simultaneously embodies the structurality, flexibility, and dynamicity. At
its core, CAM is endowed with an incremental overlapping clustering algorithm
for structured memory development, supporting both coherent hierarchical
summarization and online batch integration. During inference, CAM adaptively
explores the memory structure to activate query-relevant information for
contextual response, akin to the human associative process. Compared to
existing approaches, our design demonstrates dual advantages in both
performance and efficiency across diverse long-text reading comprehension
tasks, including question answering, query-based summarization, and claim
verification.

---

## 65. Automated Research Article Classification and Recommendation Using NLP and ML

**Authors:** Shadikur Rahman, Hasibul Karim Shanto, Umme Ayman Koana, Syed Muhammad Danish

**Published:** 2025-10-07

**Categories:** cs.IR

**PDF:** [http://arxiv.org/pdf/2510.05495v1](http://arxiv.org/pdf/2510.05495v1)

**Abstract:**

In the digital era, the exponential growth of scientific publications has
made it increasingly difficult for researchers to efficiently identify and
access relevant work. This paper presents an automated framework for research
article classification and recommendation that leverages Natural Language
Processing (NLP) techniques and machine learning. Using a large-scale arXiv.org
dataset spanning more than three decades, we evaluate multiple feature
extraction approaches (TF--IDF, Count Vectorizer, Sentence-BERT, USE,
Mirror-BERT) in combination with diverse machine learning classifiers (Logistic
Regression, SVM, Na\"ive Bayes, Random Forest, Gradient Boosted Trees, and
k-Nearest Neighbour). Our experiments show that Logistic Regression with
TF--IDF consistently yields the best classification performance, achieving an
accuracy of 69\%. To complement classification, we incorporate a recommendation
module based on the cosine similarity of vectorized articles, enabling
efficient retrieval of related research papers. The proposed system directly
addresses the challenge of information overload in digital libraries and
demonstrates a scalable, data-driven solution to support literature discovery.

---

## 66. Vul-R2: A Reasoning LLM for Automated Vulnerability Repair

**Authors:** Xin-Cheng Wen, Zirui Lin, Yijun Yang, Cuiyun Gao, Deheng Ye

**Published:** 2025-10-07

**Categories:** cs.AI, cs.SE

**PDF:** [http://arxiv.org/pdf/2510.05480v1](http://arxiv.org/pdf/2510.05480v1)

**Abstract:**

The exponential increase in software vulnerabilities has created an urgent
need for automatic vulnerability repair (AVR) solutions. Recent research has
formulated AVR as a sequence generation problem and has leveraged large
language models (LLMs) to address this problem. Typically, these approaches
prompt or fine-tune LLMs to generate repairs for vulnerabilities directly.
Although these methods show state-of-the-art performance, they face the
following challenges: (1) Lack of high-quality, vulnerability-related reasoning
data. Current approaches primarily rely on foundation models that mainly encode
general programming knowledge. Without vulnerability-related reasoning data,
they tend to fail to capture the diverse vulnerability repair patterns. (2)
Hard to verify the intermediate vulnerability repair process during LLM
training. Existing reinforcement learning methods often leverage intermediate
execution feedback from the environment (e.g., sandbox-based execution results)
to guide reinforcement learning training. In contrast, the vulnerability repair
process generally lacks such intermediate, verifiable feedback, which poses
additional challenges for model training.

---

## 67. AgentRouter: A Knowledge-Graph-Guided LLM Router for Collaborative Multi-Agent Question Answering

**Authors:** Zheyuan Zhang, Kaiwen Shi, Zhengqing Yuan, Zehong Wang, Tianyi Ma, Keerthiram Murugesan, Vincent Galassi, Chuxu Zhang, Yanfang Ye

**Published:** 2025-10-06

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05445v1](http://arxiv.org/pdf/2510.05445v1)

**Abstract:**

Large language models (LLMs) and agent-based frameworks have advanced
rapidly, enabling diverse applications. Yet, with the proliferation of models
and agentic strategies, practitioners face substantial uncertainty in selecting
the best configuration for a downstream task. Prior studies show that different
agents and backbones exhibit complementary strengths, and that larger models
are not always superior, underscoring the need for adaptive routing mechanisms.
Existing approaches to agent routing, however, often emphasize cost efficiency
while overlooking the fine-grained contextual and relational structure inherent
in QA tasks. In this paper, we propose tAgentRouter, a framework that
formulates multi-agent QA as a knowledge-graph-guided routing problem
supervised by empirical performance signals. Specifically, we convert QA
instance into a knowledge graph that jointly encodes queries, contextual
entities, and agents, and then train a heterogeneous graph neural network (GNN)
to propagate information across node types and produce task-aware routing
distributions over agents. By leveraging soft supervision and weighted
aggregation of agent outputs, AgentRouter learns principled collaboration
schemes that capture the complementary strengths of diverse agents. Extensive
experiments demonstrate that our framework consistently outperforms
single-agent and ensemble baselines, while generalizing across benchmarks and
LLM backbones. These results highlight the effectiveness and robustness of
graph-supervised multi-agent routing for question answering.

---

## 68. Adversarial Reinforcement Learning for Large Language Model Agent Safety

**Authors:** Zizhao Wang, Dingcheng Li, Vaishakh Keshava, Phillip Wallis, Ananth Balashankar, Peter Stone, Lukas Rutishauser

**Published:** 2025-10-06

**Categories:** cs.LG, cs.AI, cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05442v1](http://arxiv.org/pdf/2510.05442v1)

**Abstract:**

Large Language Model (LLM) agents can leverage tools such as Google Search to
complete complex tasks. However, this tool usage introduces the risk of
indirect prompt injections, where malicious instructions hidden in tool outputs
can manipulate the agent, posing security risks like data leakage. Current
defense strategies typically rely on fine-tuning LLM agents on datasets of
known attacks. However, the generation of these datasets relies on manually
crafted attack patterns, which limits their diversity and leaves agents
vulnerable to novel prompt injections. To address this limitation, we propose
Adversarial Reinforcement Learning for Agent Safety (ARLAS), a novel framework
that leverages adversarial reinforcement learning (RL) by formulating the
problem as a two-player zero-sum game. ARLAS co-trains two LLMs: an attacker
that learns to autonomously generate diverse prompt injections and an agent
that learns to defend against them while completing its assigned tasks. To
ensure robustness against a wide range of attacks and to prevent cyclic
learning, we employ a population-based learning framework that trains the agent
to defend against all previous attacker checkpoints. Evaluated on BrowserGym
and AgentDojo, agents fine-tuned with ARLAS achieve a significantly lower
attack success rate than the original model while also improving their task
success rate. Our analysis further confirms that the adversarial process
generates a diverse and challenging set of attacks, leading to a more robust
agent compared to the base model.

---

## 69. UnitTenX: Generating Tests for Legacy Packages with AI Agents Powered by Formal Verification

**Authors:** Yiannis Charalambous, Claudionor N. Coelho Jr, Luis Lamb, Lucas C. Cordeiro

**Published:** 2025-10-06

**Categories:** cs.SE, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05441v1](http://arxiv.org/pdf/2510.05441v1)

**Abstract:**

This paper introduces UnitTenX, a state-of-the-art open-source AI multi-agent
system designed to generate unit tests for legacy code, enhancing test coverage
and critical value testing. UnitTenX leverages a combination of AI agents,
formal methods, and Large Language Models (LLMs) to automate test generation,
addressing the challenges posed by complex and legacy codebases. Despite the
limitations of LLMs in bug detection, UnitTenX offers a robust framework for
improving software reliability and maintainability. Our results demonstrate the
effectiveness of this approach in generating high-quality tests and identifying
potential issues. Additionally, our approach enhances the readability and
documentation of legacy code.

---

## 70. AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems

**Authors:** Shambhavi Mishra, Gaurav Sahu, Marco Pedersoli, Laurent Charlin, Jose Dolz, Christopher Pal

**Published:** 2025-10-06

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05432v1](http://arxiv.org/pdf/2510.05432v1)

**Abstract:**

Large language models (LLMs) demonstrate impressive capabilities across a
wide range of tasks, yet it remains unclear whether such success reflects
genuine reasoning or sophisticated recall. We introduce AInstein, a framework
for testing whether LLMs can generate valid solutions to AI research problems
using only their pretrained parametric knowledge -- without domain-specific
fine-tuning, retrieval augmentation, or other external aids. Our approach
extracts distilled problem statements from high-quality ICLR 2025 submissions,
then tasks specialized solver agents with proposing and refining technical
solutions through iterative critique loops, mimicking the cycles of proposal,
review, and revision central to scientific inquiry. We evaluate AInstein on
1,214 ICLR papers stratified by acceptance tier (Oral, Spotlight, Poster),
using an LLM-as-a-judge paradigm guided by a structured rubric, complemented by
targeted manual checks. Performance is assessed with three metrics: Success
Rate (does the solution address the problem?), Rediscovery (does it align with
human-proposed methods?), and Novelty (does it yield valid, original
approaches?). Our results reveal that while LLMs can rediscover feasible
solutions and occasionally propose creative alternatives, their problem-solving
ability remains fragile and highly sensitive to framing. These findings provide
the first large-scale evidence on the extent to which LLMs can act as
autonomous scientific problem-solvers, highlighting both their latent potential
and their current limitations.

---

## 71. A Lightweight Large Language Model-Based Multi-Agent System for 2D Frame Structural Analysis

**Authors:** Ziheng Geng, Jiachen Liu, Ran Cao, Lu Cheng, Haifeng Wang, Minghui Cheng

**Published:** 2025-10-06

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05414v1](http://arxiv.org/pdf/2510.05414v1)

**Abstract:**

Large language models (LLMs) have recently been used to empower autonomous
agents in engineering, significantly improving automation and efficiency in
labor-intensive workflows. However, their potential remains underexplored in
structural engineering, particularly for finite element modeling tasks
requiring geometric modeling, complex reasoning, and domain knowledge. To
bridge this gap, this paper develops a LLM-based multi-agent system to automate
finite element modeling of 2D frames. The system decomposes structural analysis
into subtasks, each managed by a specialized agent powered by the lightweight
Llama-3.3 70B Instruct model. The workflow begins with a Problem Analysis
Agent, which extracts geometry, boundary, and material parameters from the user
input. Next, a Geometry Agent incrementally derives node coordinates and
element connectivity by applying expert-defined rules. These structured outputs
are converted into executable OpenSeesPy code by a Translation Agent and
refined by a Model Validation Agent through consistency checks. Then, a Load
Agent applies load conditions into the assembled structural model. Experimental
evaluations on 20 benchmark problems demonstrate that the system achieves
accuracy over 80% in most cases across 10 repeated trials, outperforming
Gemini-2.5 Pro and ChatGPT-4o models.

---

## 72. Personalizing Retrieval using Joint Embeddings or "the Return of Fluffy"

**Authors:** Bruno Korbar, Andrew Zisserman

**Published:** 2025-10-06

**Categories:** cs.CV

**PDF:** [http://arxiv.org/pdf/2510.05411v1](http://arxiv.org/pdf/2510.05411v1)

**Abstract:**

The goal of this paper is to be able to retrieve images using a compound
query that combines object instance information from an image, with a natural
text description of what that object is doing or where it is. For example, to
retrieve an image of "Fluffy the unicorn (specified by an image) on someone's
head". To achieve this we design a mapping network that can "translate" from a
local image embedding (of the object instance) to a text token, such that the
combination of the token and a natural language query is suitable for CLIP
style text encoding, and image retrieval. Generating a text token in this
manner involves a simple training procedure, that only needs to be performed
once for each object instance. We show that our approach of using a trainable
mapping network, termed pi-map, together with frozen CLIP text and image
encoders, improves the state of the art on two benchmarks designed to assess
personalized retrieval.

---

## 73. Scalable In-context Ranking with Generative Models

**Authors:** Nilesh Gupta, Chong You, Srinadh Bhojanapalli, Sanjiv Kumar, Inderjit Dhillon, Felix Yu

**Published:** 2025-10-06

**Categories:** cs.IR, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05396v1](http://arxiv.org/pdf/2510.05396v1)

**Abstract:**

In-context Ranking (ICR) is an emerging paradigm for Information Retrieval
(IR), which leverages contextual understanding of LLMs by directly
incorporating the task description, candidate documents, and the query into the
model's input prompt and tasking the LLM to identify relevant document(s).
While it is effective, efficiency is a significant challenge in this paradigm,
especially as the candidate list grows due to quadratic/super-linear scaling of
attention operation with context length. To this end, this paper first
identifies inherent and exploitable structures in the attention of LLMs
finetuned for ICR: (1) inter-document block sparsity: attention is dense within
each document block but sparse across different documents in the context; and
(2) query-document block relevance: the attention scores from certain query
tokens to a document block in middle layers strongly correlate with that
document's actual relevance. Motivated by these observations, we introduce
BlockRank (Blockwise In-context Ranking), a novel method that adapts the
attention operation in an LLM by (a) architecturally enforcing the observed
inter-document block sparsity, reducing attention complexity from quadratic to
linear without loss in performance, and (b) optimizing query-document block
relevance for true relevant documents during fine-tuning using an auxiliary
contrastive training objective, improving retrieval in attention. Experiments
on BEIR, MSMarco and NQ with Mistral-7B demonstrate that FLARE Mistral matches
or outperforms existing SOTA listwise rankers and controlled fine-tuned
baseline while being significantly more efficient at inference (4.7x for 100
MSMarco documents in context) and scaling gracefully to long-context
shortlists, around 500 documents in-context (approximately 100K context length)
within a second, presenting a scalable and effective solution for ICR.

---

## 74. Context Length Alone Hurts LLM Performance Despite Perfect Retrieval

**Authors:** Yufeng Du, Minyang Tian, Srikanth Ronanki, Subendhu Rongali, Sravan Bodapati, Aram Galstyan, Azton Wells, Roy Schwartz, Eliu A Huerta, Hao Peng

**Published:** 2025-10-06

**Categories:** cs.CL, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05381v1](http://arxiv.org/pdf/2510.05381v1)

**Abstract:**

Large language models (LLMs) often fail to scale their performance on
long-context tasks performance in line with the context lengths they support.
This gap is commonly attributed to retrieval failures -- the models' inability
to identify relevant information in the long inputs. Accordingly, recent
efforts often focus on evaluating and improving LLMs' retrieval performance: if
retrieval is perfect, a model should, in principle, perform just as well on a
long input as it does on a short one -- or should it? This paper presents
findings that the answer to this question may be negative. Our systematic
experiments across 5 open- and closed-source LLMs on math, question answering,
and coding tasks reveal that, even when models can perfectly retrieve all
relevant information, their performance still degrades substantially
(13.9%--85%) as input length increases but remains well within the models'
claimed lengths. This failure occurs even when the irrelevant tokens are
replaced with minimally distracting whitespace, and, more surprisingly, when
they are all masked and the models are forced to attend only to the relevant
tokens. A similar performance drop is observed when all relevant evidence is
placed immediately before the question. Our findings reveal a
previously-unrealized limitation: the sheer length of the input alone can hurt
LLM performance, independent of retrieval quality and without any distraction.
They motivate our simple, model-agnostic mitigation strategy that transforms a
long-context task into a short-context one by prompting the model to recite the
retrieved evidence before attempting to solve the problem. On RULER, we observe
a consistent improvement of GPT-4o up to 4% on an already strong baseline.

---

## 75. AutoDAN-Reasoning: Enhancing Strategies Exploration based Jailbreak Attacks with Test-Time Scaling

**Authors:** Xiaogeng Liu, Chaowei Xiao

**Published:** 2025-10-06

**Categories:** cs.CR, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05379v1](http://arxiv.org/pdf/2510.05379v1)

**Abstract:**

Recent advancements in jailbreaking large language models (LLMs), such as
AutoDAN-Turbo, have demonstrated the power of automated strategy discovery.
AutoDAN-Turbo employs a lifelong learning agent to build a rich library of
attack strategies from scratch. While highly effective, its test-time
generation process involves sampling a strategy and generating a single
corresponding attack prompt, which may not fully exploit the potential of the
learned strategy library. In this paper, we propose to further improve the
attack performance of AutoDAN-Turbo through test-time scaling. We introduce two
distinct scaling methods: Best-of-N and Beam Search. The Best-of-N method
generates N candidate attack prompts from a sampled strategy and selects the
most effective one based on a scorer model. The Beam Search method conducts a
more exhaustive search by exploring combinations of strategies from the library
to discover more potent and synergistic attack vectors. According to the
experiments, the proposed methods significantly boost performance, with Beam
Search increasing the attack success rate by up to 15.6 percentage points on
Llama-3.1-70B-Instruct and achieving a nearly 60\% relative improvement against
the highly robust GPT-o4-mini compared to the vanilla method.

---

## 76. MHA-RAG: Improving Efficiency, Accuracy, and Consistency by Encoding Exemplars as Soft Prompts

**Authors:** Abhinav Jain, Xinyu Yao, Thomas Reps, Christopher Jermaine

**Published:** 2025-10-06

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05363v1](http://arxiv.org/pdf/2510.05363v1)

**Abstract:**

Adapting Foundation Models to new domains with limited training data is
challenging and computationally expensive. While prior work has demonstrated
the effectiveness of using domain-specific exemplars as in-context
demonstrations, we investigate whether representing exemplars purely as text is
the most efficient, effective, and stable approach. We explore an alternative:
representing exemplars as soft prompts with an exemplar order invariant model
architecture. To this end, we introduce Multi-Head Attention
Retrieval-Augmented Generation (MHA-RAG), a framework with the number of
attention heads serving as a simple hyperparameter to control soft
prompt-generation across different tasks. Across multiple question-answering
benchmarks and model scales, MHA-RAG achieves a 20-point performance gain over
standard RAG, while cutting inference costs by a factor of 10X
GFLOPs-delivering both higher accuracy and greater efficiency, invariant to
exemplar order.

---

## 77. WeatherArchive-Bench: Benchmarking Retrieval-Augmented Reasoning for Historical Weather Archives

**Authors:** Yongan Yu, Xianda Du, Qingchen Hu, Jiahao Liang, Jingwei Ni, Dan Qiang, Kaiyu Huang, Grant McKenzie, Renee Sieber, Fengran Mo

**Published:** 2025-10-06

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05336v1](http://arxiv.org/pdf/2510.05336v1)

**Abstract:**

Historical archives on weather events are collections of enduring primary
source records that offer rich, untapped narratives of how societies have
experienced and responded to extreme weather events. These qualitative accounts
provide insights into societal vulnerability and resilience that are largely
absent from meteorological records, making them valuable for climate scientists
to understand societal responses. However, their vast scale, noisy digitized
quality, and archaic language make it difficult to transform them into
structured knowledge for climate research. To address this challenge, we
introduce WeatherArchive-Bench, the first benchmark for evaluating
retrieval-augmented generation (RAG) systems on historical weather archives.
WeatherArchive-Bench comprises two tasks: WeatherArchive-Retrieval, which
measures a system's ability to locate historically relevant passages from over
one million archival news segments, and WeatherArchive-Assessment, which
evaluates whether Large Language Models (LLMs) can classify societal
vulnerability and resilience indicators from extreme weather narratives.
Extensive experiments across sparse, dense, and re-ranking retrievers, as well
as a diverse set of LLMs, reveal that dense retrievers often fail on historical
terminology, while LLMs frequently misinterpret vulnerability and resilience
concepts. These findings highlight key limitations in reasoning about complex
societal indicators and provide insights for designing more robust
climate-focused RAG systems from archival contexts. The constructed dataset and
evaluation framework are publicly available at
https://anonymous.4open.science/r/WeatherArchive-Bench/.

---

## 78. Biomedical reasoning in action: Multi-agent System for Auditable Biomedical Evidence Synthesis

**Authors:** Oskar Wysocki, Magdalena Wysocka, Mauricio Jacobo, Harriet Unsworth, André Freitas

**Published:** 2025-10-06

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05335v1](http://arxiv.org/pdf/2510.05335v1)

**Abstract:**

We present M-Reason, a demonstration system for transparent, agent-based
reasoning and evidence integration in the biomedical domain, with a focus on
cancer research. M-Reason leverages recent advances in large language models
(LLMs) and modular agent orchestration to automate evidence retrieval,
appraisal, and synthesis across diverse biomedical data sources. Each agent
specializes in a specific evidence stream, enabling parallel processing and
fine-grained analysis. The system emphasizes explainability, structured
reporting, and user auditability, providing complete traceability from source
evidence to final conclusions. We discuss critical tradeoffs between agent
specialization, system complexity, and resource usage, as well as the
integration of deterministic code for validation. An open, interactive user
interface allows researchers to directly observe, explore and evaluate the
multi-agent workflow. Our evaluation demonstrates substantial gains in
efficiency and output consistency, highlighting M-Reason's potential as both a
practical tool for evidence synthesis and a testbed for robust multi-agent LLM
systems in scientific research, available at https://m-reason.digitalecmt.com.

---

## 79. DeepV: A Model-Agnostic Retrieval-Augmented Framework for Verilog Code Generation with a High-Quality Knowledge Base

**Authors:** Zahin Ibnat, Paul E. Calzada, Rasin Mohammed Ihtemam, Sujan Kumar Saha, Jingbo Zhou, Farimah Farahmandi, Mark Tehranipoor

**Published:** 2025-10-06

**Categories:** cs.AR, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05327v1](http://arxiv.org/pdf/2510.05327v1)

**Abstract:**

As large language models (LLMs) continue to be integrated into modern
technology, there has been an increased push towards code generation
applications, which also naturally extends to hardware design automation.
LLM-based solutions for register transfer level (RTL) code generation for
intellectual property (IP) designs have grown, especially with fine-tuned LLMs,
prompt engineering, and agentic approaches becoming popular in literature.
However, a gap has been exposed in these techniques, as they fail to integrate
novel IPs into the model's knowledge base, subsequently resulting in poorly
generated code. Additionally, as general-purpose LLMs continue to improve,
fine-tuned methods on older models will not be able to compete to produce more
accurate and efficient designs. Although some retrieval augmented generation
(RAG) techniques exist to mitigate challenges presented in fine-tuning
approaches, works tend to leverage low-quality codebases, incorporate
computationally expensive fine-tuning in the frameworks, or do not use RAG
directly in the RTL generation step. In this work, we introduce DeepV: a
model-agnostic RAG framework to generate RTL designs by enhancing context
through a large, high-quality dataset without any RTL-specific training. Our
framework benefits the latest commercial LLM, OpenAI's GPT-5, with a near 17%
increase in performance on the VerilogEval benchmark. We host DeepV for use by
the community in a Hugging Face (HF) Space:
https://huggingface.co/spaces/FICS-LLM/DeepV.

---

## 80. BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions

**Authors:** Nan Huo, Xiaohan Xu, Jinyang Li, Per Jacobsson, Shipei Lin, Bowen Qin, Binyuan Hui, Xiaolong Li, Ge Qu, Shuzheng Si, Linheng Han, Edward Alexander, Xintong Zhu, Rui Qin, Ruihan Yu, Yiyao Jin, Feige Zhou, Weihao Zhong, Yun Chen, Hongyu Liu, Chenhao Ma, Fatma Ozcan, Yannis Papakonstantinou, Reynold Cheng

**Published:** 2025-10-06

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05318v1](http://arxiv.org/pdf/2510.05318v1)

**Abstract:**

Large language models (LLMs) have demonstrated remarkable performance on
single-turn text-to-SQL tasks, but real-world database applications
predominantly require multi-turn interactions to handle ambiguous queries,
execution errors, and evolving user requirements. Existing multi-turn
benchmarks fall short by treating conversation histories as static context or
limiting evaluation to read-only operations, failing to reflect
production-grade database assistant challenges. We introduce BIRD-INTERACT, a
benchmark that restores this realism through: (1) a comprehensive interaction
environment coupling each database with a hierarchical knowledge base, metadata
files, and a function-driven user simulator, enabling models to solicit
clarifications, retrieve knowledge, and recover from errors without human
supervision; (2) two evaluation settings consisting of a pre-defined
conversational protocol (c-Interact) and an open-ended agentic setting
(a-Interact) where models autonomously decide when to query the user simulator
or explore the environment; (3) a challenging task suite covering the full CRUD
spectrum for business-intelligence and operational use cases, guarded by
executable test cases. Each task features ambiguous and follow-up sub-tasks
requiring dynamic interaction. The suite comprises BIRD-INTERACT-FULL (600
tasks, up to 11,796 interactions) for comprehensive performance assessment, and
BIRD-INTERACT-LITE (300 tasks with simplified databases) for detailed
behavioral analysis and rapid method development. Our empirical results
highlight BIRD-INTERACT's difficulty: GPT-5 completes only 8.67% of tasks in
c-Interact and 17.00% in a-Interact. Analysis via memory grafting and
Interaction Test-time Scaling validates the importance of effective interaction
for complex, dynamic text-to-SQL tasks.

---

## 81. RAG Makes Guardrails Unsafe? Investigating Robustness of Guardrails under RAG-style Contexts

**Authors:** Yining She, Daniel W. Peterson, Marianne Menglin Liu, Vikas Upadhyay, Mohammad Hossein Chaghazardi, Eunsuk Kang, Dan Roth

**Published:** 2025-10-06

**Categories:** cs.CL, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05310v1](http://arxiv.org/pdf/2510.05310v1)

**Abstract:**

With the increasing adoption of large language models (LLMs), ensuring the
safety of LLM systems has become a pressing concern. External LLM-based
guardrail models have emerged as a popular solution to screen unsafe inputs and
outputs, but they are themselves fine-tuned or prompt-engineered LLMs that are
vulnerable to data distribution shifts. In this paper, taking Retrieval
Augmentation Generation (RAG) as a case study, we investigated how robust
LLM-based guardrails are against additional information embedded in the
context. Through a systematic evaluation of 3 Llama Guards and 2 GPT-oss
models, we confirmed that inserting benign documents into the guardrail context
alters the judgments of input and output guardrails in around 11% and 8% of
cases, making them unreliable. We separately analyzed the effect of each
component in the augmented context: retrieved documents, user query, and
LLM-generated response. The two mitigation methods we tested only bring minor
improvements. These results expose a context-robustness gap in current
guardrails and motivate training and evaluation protocols that are robust to
retrieval and query composition.

---

## 82. When Should Users Check? A Decision-Theoretic Model of Confirmation Frequency in Multi-Step AI Agent Tasks

**Authors:** Jieyu Zhou, Aryan Roy, Sneh Gupta, Daniel Weitekamp, Christopher J. MacLellan

**Published:** 2025-10-06

**Categories:** cs.HC

**PDF:** [http://arxiv.org/pdf/2510.05307v1](http://arxiv.org/pdf/2510.05307v1)

**Abstract:**

Existing AI agents typically execute multi-step tasks autonomously and only
allow user confirmation at the end. During execution, users have little
control, making the confirm-at-end approach brittle: a single error can cascade
and force a complete restart. Confirming every step avoids such failures, but
imposes tedious overhead. Balancing excessive interruptions against costly
rollbacks remains an open challenge. We address this problem by modeling
confirmation as a minimum time scheduling problem. We conducted a formative
study with eight participants, which revealed a recurring
Confirmation-Diagnosis-Correction-Redo (CDCR) pattern in how users monitor
errors. Based on this pattern, we developed a decision-theoretic model to
determine time-efficient confirmation point placement. We then evaluated our
approach using a within-subjects study where 48 participants monitored AI
agents and repaired their mistakes while executing tasks. Results show that 81
percent of participants preferred our intermediate confirmation approach over
the confirm-at-end approach used by existing systems, and task completion time
was reduced by 13.54 percent.

---

## 83. Chrysalis: A Unified System for Comparing Active Teaching and Passive Learning with AI Agents in Education

**Authors:** Prashanth Arun, Vinita Vader, Erya Xu, Brent McCready-Branch, Sarah Seabrook, Kyle Scholz, Ana Crisan, Igor Grossmann, Pascal Poupart

**Published:** 2025-10-06

**Categories:** cs.HC

**PDF:** [http://arxiv.org/pdf/2510.05271v1](http://arxiv.org/pdf/2510.05271v1)

**Abstract:**

AI-assisted learning has seen a remarkable uptick over the last few years,
mainly due to the rise in popularity of Large Language Models (LLMs). Their
ability to hold long-form, natural language interactions with users makes them
excellent resources for exploring school- and university-level topics in a
dynamic, active manner. We compare students' experiences when interacting with
an LLM companion in two capacities: tutored learning and learning-by-teaching.
We do this using Chrysalis, an LLM-based system that we have designed to
support both AI tutors and AI teachable agents for any topic. Through a
within-subject exploratory study with 36 participants, we present insights into
student preferences between the two strategies and how constructs such as
intellectual humility vary between these two interaction modes. To our
knowledge, we are the first to conduct a direct comparison study on the effects
of using an LLM as a tutor versus as a teachable agent on multiple topics. We
hope that our work opens up new avenues for future research in this area.

---

## 84. VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing

**Authors:** Yixiao Wang, Mingxiao Huo, Zhixuan Liang, Yushi Du, Lingfeng Sun, Haotian Lin, Jinghuan Shang, Chensheng Peng, Mohit Bansal, Mingyu Ding, Masayoshi Tomizuka

**Published:** 2025-10-06

**Categories:** cs.RO, cs.AI, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.05213v1](http://arxiv.org/pdf/2510.05213v1)

**Abstract:**

Pretrained vision foundation models (VFMs) advance robotic learning via rich
visual representations, yet individual VFMs typically excel only in specific
domains, limiting generality across tasks. Distilling multiple VFMs into a
unified representation for policy can mitigate this limitation but often yields
inflexible task-specific feature selection and requires costly full re-training
to incorporate robot-domain knowledge. We propose VER, a Vision Expert
transformer for Robot learning. During pretraining, VER distills multiple VFMs
into a vision expert library. It then fine-tunes only a lightweight routing
network (fewer than 0.4% of parameters) to dynamically select task-relevant
experts from the pretrained library for downstream robot tasks. We further
introduce Patchwise Expert Routing with Curriculum Top-K Annealing to improve
both flexibility and precision of dynamic expert selection. Moreover, VER
supports parameter-efficient finetuning for scalable expert utilization and
adaptive robot-domain knowledge integration. Across 17 diverse robotic tasks
and multiple policy heads, VER achieves state-of-the-art performance. We find
that VER reduces large-norm outliers in task-irrelevant regions (e.g.,
background) and concentrates on task-critical regions. Visualizations and codes
can be found in https://yixiaowang7.github.io/ver_page/.

---

## 85. Paper2Video: Automatic Video Generation from Scientific Papers

**Authors:** Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou

**Published:** 2025-10-06

**Categories:** cs.CV, cs.AI, cs.CL, cs.MA, cs.MM

**PDF:** [http://arxiv.org/pdf/2510.05096v1](http://arxiv.org/pdf/2510.05096v1)

**Abstract:**

Academic presentation videos have become an essential medium for research
communication, yet producing them remains highly labor-intensive, often
requiring hours of slide design, recording, and editing for a short 2 to 10
minutes video. Unlike natural video, presentation video generation involves
distinctive challenges: inputs from research papers, dense multi-modal
information (text, figures, tables), and the need to coordinate multiple
aligned channels such as slides, subtitles, speech, and human talker. To
address these challenges, we introduce PaperTalker, the first benchmark of 101
research papers paired with author-created presentation videos, slides, and
speaker metadata. We further design four tailored evaluation metrics--Meta
Similarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos
convey the paper's information to the audience. Building on this foundation, we
propose PaperTalker, the first multi-agent framework for academic presentation
video generation. It integrates slide generation with effective layout
refinement by a novel effective tree search visual choice, cursor grounding,
subtitling, speech synthesis, and talking-head rendering, while parallelizing
slide-wise generation for efficiency. Experiments on Paper2Video demonstrate
that the presentation videos produced by our approach are more faithful and
informative than existing baselines, establishing a practical step toward
automated and ready-to-use academic video generation. Our dataset, agent, and
code are available at https://github.com/showlab/Paper2Video.

---

## 86. Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces

**Authors:** Debojyoti Ghosh, Soumya K Ghosh, Adrijit Goswami

**Published:** 2025-10-06

**Categories:** cs.CV

**PDF:** [http://arxiv.org/pdf/2510.05071v1](http://arxiv.org/pdf/2510.05071v1)

**Abstract:**

Efficient and accurate classification of waste and industrial surface defects
is essential for ensuring sustainable waste management and maintaining high
standards in quality control. This paper introduces the Neuroplastic Modular
Classifier, a novel hybrid architecture designed for robust and adaptive image
classification in dynamic environments. The model combines a ResNet-50 backbone
for localized feature extraction with a Vision Transformer (ViT) to capture
global semantic context. Additionally, FAISS-based similarity retrieval is
incorporated to provide a memory-like reference to previously encountered data,
enriching the model's feature space. A key innovation of our architecture is
the neuroplastic modular design composed of expandable, learnable blocks that
dynamically grow during training when performance plateaus. Inspired by
biological learning systems, this mechanism allows the model to adapt to data
complexity over time, improving generalization. Beyond garbage classification,
we validate the model on the Kolektor Surface Defect Dataset 2 (KolektorSDD2),
which involves industrial defect detection on metal surfaces. Experimental
results across domains show that the proposed architecture outperforms
traditional static models in both accuracy and adaptability. The Neuroplastic
Modular Classifier offers a scalable, high-performance solution for real-world
image classification, with strong applicability in both environmental and
industrial domains.

---

## 87. Multi-Agent Distributed Optimization With Feasible Set Privacy

**Authors:** Shreya Meel, Sennur Ulukus

**Published:** 2025-10-06

**Categories:** cs.IT, cs.CR, cs.DC, cs.NI, eess.SP, math.IT

**PDF:** [http://arxiv.org/pdf/2510.05068v1](http://arxiv.org/pdf/2510.05068v1)

**Abstract:**

We consider the problem of decentralized constrained optimization with
multiple agents $E_1,\ldots,E_N$ who jointly wish to learn the optimal solution
set while keeping their feasible sets $\mathcal{P}_1,\ldots,\mathcal{P}_N$
private from each other. We assume that the objective function $f$ is known to
all agents and each feasible set is a collection of points from a universal
alphabet $\mathcal{P}_{alph}$. A designated agent (leader) starts the
communication with the remaining (non-leader) agents, and is the first to
retrieve the solution set. The leader searches for the solution by sending
queries to and receiving answers from the non-leaders, such that the
information on the individual feasible sets revealed to the leader should be no
more than nominal, i.e., what is revealed from learning the solution set alone.
We develop achievable schemes for obtaining the solution set at nominal
information leakage, and characterize their communication costs under two
communication setups between agents. In this work, we focus on two kinds of
network setups: i) ring, where each agent communicates with two adjacent
agents, and ii) star, where only the leader communicates with the remaining
agents. We show that, if the leader first learns the joint feasible set through
an existing private set intersection (PSI) protocol and then deduces the
solution set, the information leaked to the leader is greater than nominal.
Moreover, we draw connection of our schemes to threshold PSI (ThPSI), which is
a PSI-variant where the intersection is revealed only when its cardinality is
larger than a threshold value. Finally, for various realizations of $f$ mapped
uniformly at random to a fixed range of values, our schemes are more
communication-efficient with a high probability compared to retrieving the
entire feasible set through PSI.

---

## 88. Staircase Streaming for Low-Latency Multi-Agent Inference

**Authors:** Junlin Wang, Jue Wang, Zhen, Xu, Ben Athiwaratkun, Bhuwan Dhingra, Ce Zhang, James Zou

**Published:** 2025-10-06

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05059v1](http://arxiv.org/pdf/2510.05059v1)

**Abstract:**

Recent advances in large language models (LLMs) opened up new directions for
leveraging the collective expertise of multiple LLMs. These methods, such as
Mixture-of-Agents, typically employ additional inference steps to generate
intermediate outputs, which are then used to produce the final response. While
multi-agent inference can enhance response quality, it can significantly
increase the time to first token (TTFT), posing a challenge for
latency-sensitive applications and hurting user experience. To address this
issue, we propose staircase streaming for low-latency multi-agent inference.
Instead of waiting for the complete intermediate outputs from previous steps,
we begin generating the final response as soon as we receive partial outputs
from these steps. Experimental results demonstrate that staircase streaming
reduces TTFT by up to 93% while maintaining response quality.

---

## 89. SegMASt3R: Geometry Grounded Segment Matching

**Authors:** Rohit Jayanti, Swayam Agrawal, Vansh Garg, Siddharth Tourani, Muhammad Haris Khan, Sourav Garg, Madhava Krishna

**Published:** 2025-10-06

**Categories:** cs.CV

**PDF:** [http://arxiv.org/pdf/2510.05051v1](http://arxiv.org/pdf/2510.05051v1)

**Abstract:**

Segment matching is an important intermediate task in computer vision that
establishes correspondences between semantically or geometrically coherent
regions across images. Unlike keypoint matching, which focuses on localized
features, segment matching captures structured regions, offering greater
robustness to occlusions, lighting variations, and viewpoint changes. In this
paper, we leverage the spatial understanding of 3D foundation models to tackle
wide-baseline segment matching, a challenging setting involving extreme
viewpoint shifts. We propose an architecture that uses the inductive bias of
these 3D foundation models to match segments across image pairs with up to 180
degree view-point change. Extensive experiments show that our approach
outperforms state-of-the-art methods, including the SAM2 video propagator and
local feature matching methods, by upto 30% on the AUPRC metric, on ScanNet++
and Replica datasets. We further demonstrate benefits of the proposed model on
relevant downstream tasks, including 3D instance segmentation and image-goal
navigation. Project Page: https://segmast3r.github.io/

---

## 90. Look-ahead Reasoning with a Learned Model in Imperfect Information Games

**Authors:** Ondřej Kubíček, Viliam Lisý

**Published:** 2025-10-06

**Categories:** cs.AI, cs.GT

**PDF:** [http://arxiv.org/pdf/2510.05048v1](http://arxiv.org/pdf/2510.05048v1)

**Abstract:**

Test-time reasoning significantly enhances pre-trained AI agents'
performance. However, it requires an explicit environment model, often
unavailable or overly complex in real-world scenarios. While MuZero enables
effective model learning for search in perfect information games, extending
this paradigm to imperfect information games presents substantial challenges
due to more nuanced look-ahead reasoning techniques and large number of states
relevant for individual decisions. This paper introduces an algorithm LAMIR
that learns an abstracted model of an imperfect information game directly from
the agent-environment interaction. During test time, this trained model is used
to perform look-ahead reasoning. The learned abstraction limits the size of
each subgame to a manageable size, making theoretically principled look-ahead
reasoning tractable even in games where previous methods could not scale. We
empirically demonstrate that with sufficient capacity, LAMIR learns the exact
underlying game structure, and with limited capacity, it still learns a
valuable abstraction, which improves game playing performance of the
pre-trained agents even in large games.

---

## 91. Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization

**Authors:** Omri Uzan, Asaf Yehudai, Roi pony, Eyal Shnarch, Ariel Gera

**Published:** 2025-10-06

**Categories:** cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05038v1](http://arxiv.org/pdf/2510.05038v1)

**Abstract:**

Multimodal encoders have pushed the boundaries of visual document retrieval,
matching textual query tokens directly to image patches and achieving
state-of-the-art performance on public benchmarks. Recent models relying on
this paradigm have massively scaled the sizes of their query and document
representations, presenting obstacles to deployment and scalability in
real-world pipelines. Furthermore, purely vision-centric approaches may be
constrained by the inherent modality gap still exhibited by modern
vision-language models. In this work, we connect these challenges to the
paradigm of hybrid retrieval, investigating whether a lightweight dense text
retriever can enhance a stronger vision-centric model. Existing hybrid methods,
which rely on coarse-grained fusion of ranks or scores, fail to exploit the
rich interactions within each model's representation space. To address this, we
introduce Guided Query Refinement (GQR), a novel test-time optimization method
that refines a primary retriever's query embedding using guidance from a
complementary retriever's scores. Through extensive experiments on visual
document retrieval benchmarks, we demonstrate that GQR allows vision-centric
models to match the performance of models with significantly larger
representations, while being up to 14x faster and requiring 54x less memory.
Our findings show that GQR effectively pushes the Pareto frontier for
performance and efficiency in multimodal retrieval. We release our code at
https://github.com/IBM/test-time-hybrid-retrieval

---

## 92. Large Language Models Achieve Gold Medal Performance at the International Olympiad on Astronomy & Astrophysics (IOAA)

**Authors:** Lucas Carrit Delgado Pinheiro, Ziru Chen, Bruno Caixeta Piazza, Ness Shroff, Yingbin Liang, Yuan-Sen Ting, Huan Sun

**Published:** 2025-10-06

**Categories:** astro-ph.IM, cs.AI, cs.CL

**PDF:** [http://arxiv.org/pdf/2510.05016v2](http://arxiv.org/pdf/2510.05016v2)

**Abstract:**

While task-specific demonstrations show early success in applying large
language models (LLMs) to automate some astronomical research tasks, they only
provide incomplete views of all necessary capabilities in solving astronomy
problems, calling for more thorough understanding of LLMs' strengths and
limitations. So far, existing benchmarks and evaluations focus on simple
question-answering that primarily tests astronomical knowledge and fails to
evaluate the complex reasoning required for real-world research in the
discipline. Here, we address this gap by systematically benchmarking five
state-of-the-art LLMs on the International Olympiad on Astronomy and
Astrophysics (IOAA) exams, which are designed to examine deep conceptual
understanding, multi-step derivations, and multimodal analysis. With average
scores of 85.6% and 84.2%, Gemini 2.5 Pro and GPT-5 (the two top-performing
models) not only achieve gold medal level performance but also rank in the top
two among ~200-300 participants in all four IOAA theory exams evaluated
(2022-2025). In comparison, results on the data analysis exams show more
divergence. GPT-5 still excels in the exams with an 88.5% average score,
ranking top 10 among the participants in the four most recent IOAAs, while
other models' performances drop to 48-76%. Furthermore, our in-depth error
analysis underscores conceptual reasoning, geometric reasoning, and spatial
visualization (52-79% accuracy) as consistent weaknesses among all LLMs. Hence,
although LLMs approach peak human performance in theory exams, critical gaps
must be addressed before they can serve as autonomous research agents in
astronomy.

---

## 93. Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning

**Authors:** Imran Mansha

**Published:** 2025-10-06

**Categories:** cs.CL, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05003v1](http://arxiv.org/pdf/2510.05003v1)

**Abstract:**

Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstrated
remarkable reasoning abilities but require significant computational resources
for fine-tuning. This paper presents a resource-efficient fine-tuning approach
for LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operating
under constrained GPU and memory settings. Using parameter-efficient tuning
techniques such as LoRA and QLoRA, we adapt the base model on publicly
available medical reasoning datasets. The model achieves improved reasoning
coherence and factual accuracy while reducing memory usage by up to 60%
compared to standard full fine-tuning. Experimental evaluation demonstrates
that lightweight adaptations can retain strong reasoning capability in medical
question-answering tasks. This work highlights practical strategies for
deploying LLMs in low-resource research environments and provides insights into
balancing efficiency and domain specialization for medical AI systems.

---

## 94. LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game

**Authors:** Fangzhou Liang, Tianshi Zheng, Chunkit Chan, Yauwai Yim, Yangqiu Song

**Published:** 2025-10-06

**Categories:** cs.AI, cs.CL

**PDF:** [http://arxiv.org/pdf/2510.04980v1](http://arxiv.org/pdf/2510.04980v1)

**Abstract:**

Effective multi-agent collaboration requires agents to infer the rationale
behind others' actions, a capability rooted in Theory-of-Mind (ToM). While
recent Large Language Models (LLMs) excel at logical inference, their ability
to infer rationale in dynamic, collaborative settings remains under-explored.
This study introduces LLM-Hanabi, a novel benchmark that uses the cooperative
game Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework
features an automated evaluation system that measures both game performance and
ToM proficiency. Across a range of models, we find a significant positive
correlation between ToM and in-game success. Notably, first-order ToM
(interpreting others' intent) correlates more strongly with performance than
second-order ToM (predicting others' interpretations). These findings highlight
that for effective AI collaboration, the ability to accurately interpret a
partner's rationale is more critical than higher-order reasoning. We conclude
that prioritizing first-order ToM is a promising direction for enhancing the
collaborative capabilities of future models.

---

## 95. Graph-based LLM over Semi-Structured Population Data for Dynamic Policy Response

**Authors:** Daqian Shi, Xiaolei Diao, Jinge Wu, Honghan Wu, Xiongfeng Tang, Felix Naughton, Paulina Bondaronek

**Published:** 2025-10-06

**Categories:** cs.AI

**PDF:** [http://arxiv.org/pdf/2510.05196v1](http://arxiv.org/pdf/2510.05196v1)

**Abstract:**

Timely and accurate analysis of population-level data is crucial for
effective decision-making during public health emergencies such as the COVID-19
pandemic. However, the massive input of semi-structured data, including
structured demographic information and unstructured human feedback, poses
significant challenges to conventional analysis methods. Manual expert-driven
assessments, though accurate, are inefficient, while standard NLP pipelines
often require large task-specific labeled datasets and struggle with
generalization across diverse domains. To address these challenges, we propose
a novel graph-based reasoning framework that integrates large language models
with structured demographic attributes and unstructured public feedback in a
weakly supervised pipeline. The proposed approach dynamically models evolving
citizen needs into a need-aware graph, enabling population-specific analyses
based on key features such as age, gender, and the Index of Multiple
Deprivation. It generates interpretable insights to inform responsive health
policy decision-making. We test our method using a real-world dataset, and
preliminary experimental results demonstrate its feasibility. This approach
offers a scalable solution for intelligent population health monitoring in
resource-constrained clinical and governmental settings.

---

## 96. ActiveMark: on watermarking of visual foundation models via massive activations

**Authors:** Anna Chistyakova, Mikhail Pautov

**Published:** 2025-10-06

**Categories:** cs.CV, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.04966v1](http://arxiv.org/pdf/2510.04966v1)

**Abstract:**

Being trained on large and vast datasets, visual foundation models (VFMs) can
be fine-tuned for diverse downstream tasks, achieving remarkable performance
and efficiency in various computer vision applications. The high computation
cost of data collection and training motivates the owners of some VFMs to
distribute them alongside the license to protect their intellectual property
rights. However, a dishonest user of the protected model's copy may illegally
redistribute it, for example, to make a profit. As a consequence, the
development of reliable ownership verification tools is of great importance
today, since such methods can be used to differentiate between a redistributed
copy of the protected model and an independent model. In this paper, we propose
an approach to ownership verification of visual foundation models by
fine-tuning a small set of expressive layers of a VFM along with a small
encoder-decoder network to embed digital watermarks into an internal
representation of a hold-out set of input images. Importantly, the watermarks
embedded remain detectable in the functional copies of the protected model,
obtained, for example, by fine-tuning the VFM for a particular downstream task.
Theoretically and experimentally, we demonstrate that the proposed method
yields a low probability of false detection of a non-watermarked model and a
low probability of false misdetection of a watermarked model.

---

## 97. Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits

**Authors:** Ailiya Borjigin, Cong He

**Published:** 2025-10-06

**Categories:** cs.AI, cs.DC

**PDF:** [http://arxiv.org/pdf/2510.04952v2](http://arxiv.org/pdf/2510.04952v2)

**Abstract:**

We present a cross-market algorithmic trading system that balances execution
quality with rigorous compliance enforcement. The architecture comprises a
high-level planner, a reinforcement learning execution agent, and an
independent compliance agent. We formulate trade execution as a constrained
Markov decision process with hard constraints on participation limits, price
bands, and self-trading avoidance. The execution agent is trained with proximal
policy optimization, while a runtime action-shield projects any unsafe action
into a feasible set. To support auditability without exposing proprietary
signals, we add a zero-knowledge compliance audit layer that produces
cryptographic proofs that all actions satisfied the constraints. We evaluate in
a multi-venue, ABIDES-based simulator and compare against standard baselines
(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and
variance while exhibiting no observed constraint violations across stress
scenarios including elevated latency, partial fills, compliance module
toggling, and varying constraint limits. We report effects at the 95%
confidence level using paired t-tests and examine tail risk via CVaR. We
situate the work at the intersection of optimal execution, safe reinforcement
learning, regulatory technology, and verifiable AI, and discuss ethical
considerations, limitations (e.g., modeling assumptions and computational
overhead), and paths to real-world deployment.

---

## 98. MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning

**Authors:** Guoxin Chen, Zile Qiao, Wenqing Wang, Donglei Yu, Xuanzhong Chen, Hao Sun, Minpeng Liao, Kai Fan, Yong Jiang, Penguin Xie, Wayne Xin Zhao, Ruihua Song, Fei Huang

**Published:** 2025-10-06

**Categories:** cs.AI, cs.CL, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.04935v1](http://arxiv.org/pdf/2510.04935v1)

**Abstract:**

Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in
simple tasks, where the models excessively utilize System 2-type, deliberate
reasoning, leading to inefficient token generation. Furthermore, these models
face challenges in adapting their reasoning capabilities to rapidly changing
environments due to the static nature of their pretraining data. To address
these issues, advancing Large Language Models (LLMs) for complex reasoning
tasks requires innovative approaches that bridge intuitive and deliberate
cognitive processes, akin to human cognition's dual-system dynamic. This paper
introduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless
integration of System 1's fast, intuitive thinking with System 2's deliberate
reasoning within LLMs. MARS strategically integrates multiple external tools,
such as Google Search, Google Scholar, and Python Interpreter, to access
up-to-date information and execute complex computations, while creating a
specialized division of labor where System 1 efficiently processes and
summarizes high-volume external information, providing distilled insights that
expand System 2's reasoning context without overwhelming its capacity.
Furthermore, we propose a multi-agent reinforcement learning framework
extending Group Relative Policy Optimization to simultaneously optimize both
systems with multi-turn tool interactions, bin-packing optimization, and sample
balancing strategies that enhance collaborative efficiency. Extensive
experiments demonstrate MARS achieves substantial improvements of 3.86% on the
challenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%
across 7 knowledge-intensive tasks, validating the effectiveness of our
dual-system paradigm for complex reasoning in dynamic information environments.

---

## 99. Comparative Analysis of YOLOv5, Faster R-CNN, SSD, and RetinaNet for Motorbike Detection in Kigali Autonomous Driving Context

**Authors:** Ngeyen Yinkfu, Sunday Nwovu, Jonathan Kayizzi, Angelique Uwamahoro

**Published:** 2025-10-06

**Categories:** cs.CV, cs.LG

**PDF:** [http://arxiv.org/pdf/2510.04912v1](http://arxiv.org/pdf/2510.04912v1)

**Abstract:**

In Kigali, Rwanda, motorcycle taxis are a primary mode of transportation,
often navigating unpredictably and disregarding traffic rules, posing
significant challenges for autonomous driving systems. This study compares four
object detection models--YOLOv5, Faster R-CNN, SSD, and RetinaNet--for
motorbike detection using a custom dataset of 198 images collected in Kigali.
Implemented in PyTorch with transfer learning, the models were evaluated for
accuracy, localization, and inference speed to assess their suitability for
real-time navigation in resource-constrained settings. We identify
implementation challenges, including dataset limitations and model
complexities, and recommend simplified architectures for future work to enhance
accessibility for autonomous systems in developing countries like Rwanda.

---

## 100. Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches

**Authors:** Yicheng Tao, Yao Qin, Yepang Liu

**Published:** 2025-10-06

**Categories:** cs.SE, cs.CL

**PDF:** [http://arxiv.org/pdf/2510.04905v1](http://arxiv.org/pdf/2510.04905v1)

**Abstract:**

Recent advancements in large language models (LLMs) have substantially
improved automated code generation. While function-level and file-level
generation have achieved promising results, real-world software development
typically requires reasoning across entire repositories. This gives rise to the
challenging task of Repository-Level Code Generation (RLCG), where models must
capture long-range dependencies, ensure global semantic consistency, and
generate coherent code spanning multiple files or modules. To address these
challenges, Retrieval-Augmented Generation (RAG) has emerged as a powerful
paradigm that integrates external retrieval mechanisms with LLMs, enhancing
context-awareness and scalability. In this survey, we provide a comprehensive
review of research on Retrieval-Augmented Code Generation (RACG), with an
emphasis on repository-level approaches. We categorize existing work along
several dimensions, including generation strategies, retrieval modalities,
model architectures, training paradigms, and evaluation protocols. Furthermore,
we summarize widely used datasets and benchmarks, analyze current limitations,
and outline key challenges and opportunities for future research. Our goal is
to establish a unified analytical framework for understanding this rapidly
evolving field and to inspire continued progress in AI-powered software
engineering.

---

## 101. Focused Skill Discovery: Learning to Control Specific State Variables while Minimizing Side Effects

**Authors:** Jonathan Colaço Carr, Qinyi Sun, Cameron Allen

**Published:** 2025-10-06

**Categories:** cs.LG, cs.AI

**PDF:** [http://arxiv.org/pdf/2510.04901v1](http://arxiv.org/pdf/2510.04901v1)

**Abstract:**

Skills are essential for unlocking higher levels of problem solving. A common
approach to discovering these skills is to learn ones that reliably reach
different states, thus empowering the agent to control its environment.
However, existing skill discovery algorithms often overlook the natural state
variables present in many reinforcement learning problems, meaning that the
discovered skills lack control of specific state variables. This can
significantly hamper exploration efficiency, make skills more challenging to
learn with, and lead to negative side effects in downstream tasks when the goal
is under-specified. We introduce a general method that enables these skill
discovery algorithms to learn focused skills -- skills that target and control
specific state variables. Our approach improves state space coverage by a
factor of three, unlocks new learning capabilities, and automatically avoids
negative side effects in downstream tasks.

---

